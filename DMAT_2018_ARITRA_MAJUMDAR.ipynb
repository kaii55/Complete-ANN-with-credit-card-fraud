{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing Important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>80746.806911</td>\n",
       "      <td>-4.771948</td>\n",
       "      <td>3.623778</td>\n",
       "      <td>-7.033281</td>\n",
       "      <td>4.542029</td>\n",
       "      <td>-3.151225</td>\n",
       "      <td>-1.397737</td>\n",
       "      <td>-5.568731</td>\n",
       "      <td>0.570636</td>\n",
       "      <td>-2.581123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713588</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>-0.040308</td>\n",
       "      <td>-0.105130</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>0.051648</td>\n",
       "      <td>0.170575</td>\n",
       "      <td>0.075667</td>\n",
       "      <td>122.211321</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47835.365138</td>\n",
       "      <td>6.783687</td>\n",
       "      <td>4.291216</td>\n",
       "      <td>7.110937</td>\n",
       "      <td>2.873318</td>\n",
       "      <td>5.372468</td>\n",
       "      <td>1.858124</td>\n",
       "      <td>7.206773</td>\n",
       "      <td>6.797831</td>\n",
       "      <td>2.500896</td>\n",
       "      <td>...</td>\n",
       "      <td>3.869304</td>\n",
       "      <td>1.494602</td>\n",
       "      <td>1.579642</td>\n",
       "      <td>0.515577</td>\n",
       "      <td>0.797205</td>\n",
       "      <td>0.471679</td>\n",
       "      <td>1.376766</td>\n",
       "      <td>0.547291</td>\n",
       "      <td>256.683288</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>406.000000</td>\n",
       "      <td>-30.552380</td>\n",
       "      <td>-8.402154</td>\n",
       "      <td>-31.103685</td>\n",
       "      <td>-1.313275</td>\n",
       "      <td>-22.105532</td>\n",
       "      <td>-6.406267</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-41.044261</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.797604</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>-19.254328</td>\n",
       "      <td>-2.028024</td>\n",
       "      <td>-4.781606</td>\n",
       "      <td>-1.152671</td>\n",
       "      <td>-7.263482</td>\n",
       "      <td>-1.869290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41241.500000</td>\n",
       "      <td>-6.036063</td>\n",
       "      <td>1.188226</td>\n",
       "      <td>-8.643489</td>\n",
       "      <td>2.373050</td>\n",
       "      <td>-4.792835</td>\n",
       "      <td>-2.501511</td>\n",
       "      <td>-7.965295</td>\n",
       "      <td>-0.195336</td>\n",
       "      <td>-3.872383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041787</td>\n",
       "      <td>-0.533764</td>\n",
       "      <td>-0.342175</td>\n",
       "      <td>-0.436809</td>\n",
       "      <td>-0.314348</td>\n",
       "      <td>-0.259416</td>\n",
       "      <td>-0.020025</td>\n",
       "      <td>-0.108868</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>75568.500000</td>\n",
       "      <td>-2.342497</td>\n",
       "      <td>2.717869</td>\n",
       "      <td>-5.075257</td>\n",
       "      <td>4.177147</td>\n",
       "      <td>-1.522962</td>\n",
       "      <td>-1.424616</td>\n",
       "      <td>-3.034402</td>\n",
       "      <td>0.621508</td>\n",
       "      <td>-2.208768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592146</td>\n",
       "      <td>0.048434</td>\n",
       "      <td>-0.073135</td>\n",
       "      <td>-0.060795</td>\n",
       "      <td>0.088371</td>\n",
       "      <td>0.004321</td>\n",
       "      <td>0.394926</td>\n",
       "      <td>0.146344</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>128483.000000</td>\n",
       "      <td>-0.419200</td>\n",
       "      <td>4.971257</td>\n",
       "      <td>-2.276185</td>\n",
       "      <td>6.348729</td>\n",
       "      <td>0.214562</td>\n",
       "      <td>-0.413216</td>\n",
       "      <td>-0.945954</td>\n",
       "      <td>1.764879</td>\n",
       "      <td>-0.787850</td>\n",
       "      <td>...</td>\n",
       "      <td>1.244611</td>\n",
       "      <td>0.617474</td>\n",
       "      <td>0.308378</td>\n",
       "      <td>0.285328</td>\n",
       "      <td>0.456515</td>\n",
       "      <td>0.396733</td>\n",
       "      <td>0.826029</td>\n",
       "      <td>0.381152</td>\n",
       "      <td>105.890000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>170348.000000</td>\n",
       "      <td>2.132386</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>2.250210</td>\n",
       "      <td>12.114672</td>\n",
       "      <td>11.095089</td>\n",
       "      <td>6.474115</td>\n",
       "      <td>5.802537</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>3.353525</td>\n",
       "      <td>...</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>8.361985</td>\n",
       "      <td>5.466230</td>\n",
       "      <td>1.091435</td>\n",
       "      <td>2.208209</td>\n",
       "      <td>2.745261</td>\n",
       "      <td>3.052358</td>\n",
       "      <td>1.779364</td>\n",
       "      <td>2125.870000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time          V1          V2          V3          V4  \\\n",
       "count     492.000000  492.000000  492.000000  492.000000  492.000000   \n",
       "mean    80746.806911   -4.771948    3.623778   -7.033281    4.542029   \n",
       "std     47835.365138    6.783687    4.291216    7.110937    2.873318   \n",
       "min       406.000000  -30.552380   -8.402154  -31.103685   -1.313275   \n",
       "25%     41241.500000   -6.036063    1.188226   -8.643489    2.373050   \n",
       "50%     75568.500000   -2.342497    2.717869   -5.075257    4.177147   \n",
       "75%    128483.000000   -0.419200    4.971257   -2.276185    6.348729   \n",
       "max    170348.000000    2.132386   22.057729    2.250210   12.114672   \n",
       "\n",
       "               V5          V6          V7          V8          V9  ...    \\\n",
       "count  492.000000  492.000000  492.000000  492.000000  492.000000  ...     \n",
       "mean    -3.151225   -1.397737   -5.568731    0.570636   -2.581123  ...     \n",
       "std      5.372468    1.858124    7.206773    6.797831    2.500896  ...     \n",
       "min    -22.105532   -6.406267  -43.557242  -41.044261  -13.434066  ...     \n",
       "25%     -4.792835   -2.501511   -7.965295   -0.195336   -3.872383  ...     \n",
       "50%     -1.522962   -1.424616   -3.034402    0.621508   -2.208768  ...     \n",
       "75%      0.214562   -0.413216   -0.945954    1.764879   -0.787850  ...     \n",
       "max     11.095089    6.474115    5.802537   20.007208    3.353525  ...     \n",
       "\n",
       "              V21         V22         V23         V24         V25         V26  \\\n",
       "count  492.000000  492.000000  492.000000  492.000000  492.000000  492.000000   \n",
       "mean     0.713588    0.014049   -0.040308   -0.105130    0.041449    0.051648   \n",
       "std      3.869304    1.494602    1.579642    0.515577    0.797205    0.471679   \n",
       "min    -22.797604   -8.887017  -19.254328   -2.028024   -4.781606   -1.152671   \n",
       "25%      0.041787   -0.533764   -0.342175   -0.436809   -0.314348   -0.259416   \n",
       "50%      0.592146    0.048434   -0.073135   -0.060795    0.088371    0.004321   \n",
       "75%      1.244611    0.617474    0.308378    0.285328    0.456515    0.396733   \n",
       "max     27.202839    8.361985    5.466230    1.091435    2.208209    2.745261   \n",
       "\n",
       "              V27         V28       Amount  Class  \n",
       "count  492.000000  492.000000   492.000000  492.0  \n",
       "mean     0.170575    0.075667   122.211321    1.0  \n",
       "std      1.376766    0.547291   256.683288    0.0  \n",
       "min     -7.263482   -1.869290     0.000000    1.0  \n",
       "25%     -0.020025   -0.108868     1.000000    1.0  \n",
       "50%      0.394926    0.146344     9.250000    1.0  \n",
       "75%      0.826029    0.381152   105.890000    1.0  \n",
       "max      3.052358    1.779364  2125.870000    1.0  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Class']==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94838.202258</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>-0.006271</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>-0.007860</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>88.291022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47484.015786</td>\n",
       "      <td>1.929814</td>\n",
       "      <td>1.636146</td>\n",
       "      <td>1.459429</td>\n",
       "      <td>1.399333</td>\n",
       "      <td>1.356952</td>\n",
       "      <td>1.329913</td>\n",
       "      <td>1.178812</td>\n",
       "      <td>1.161283</td>\n",
       "      <td>1.089372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716743</td>\n",
       "      <td>0.723668</td>\n",
       "      <td>0.621541</td>\n",
       "      <td>0.605776</td>\n",
       "      <td>0.520673</td>\n",
       "      <td>0.482241</td>\n",
       "      <td>0.399847</td>\n",
       "      <td>0.329570</td>\n",
       "      <td>250.105092</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-31.764946</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-6.290730</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54230.000000</td>\n",
       "      <td>-0.917544</td>\n",
       "      <td>-0.599473</td>\n",
       "      <td>-0.884541</td>\n",
       "      <td>-0.850077</td>\n",
       "      <td>-0.689398</td>\n",
       "      <td>-0.766847</td>\n",
       "      <td>-0.551442</td>\n",
       "      <td>-0.208633</td>\n",
       "      <td>-0.640412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228509</td>\n",
       "      <td>-0.542403</td>\n",
       "      <td>-0.161702</td>\n",
       "      <td>-0.354425</td>\n",
       "      <td>-0.317145</td>\n",
       "      <td>-0.327074</td>\n",
       "      <td>-0.070852</td>\n",
       "      <td>-0.052950</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84711.000000</td>\n",
       "      <td>0.020023</td>\n",
       "      <td>0.064070</td>\n",
       "      <td>0.182158</td>\n",
       "      <td>-0.022405</td>\n",
       "      <td>-0.053457</td>\n",
       "      <td>-0.273123</td>\n",
       "      <td>0.041138</td>\n",
       "      <td>0.022041</td>\n",
       "      <td>-0.049964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029821</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>-0.011147</td>\n",
       "      <td>0.041082</td>\n",
       "      <td>0.016417</td>\n",
       "      <td>-0.052227</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139333.000000</td>\n",
       "      <td>1.316218</td>\n",
       "      <td>0.800446</td>\n",
       "      <td>1.028372</td>\n",
       "      <td>0.737624</td>\n",
       "      <td>0.612181</td>\n",
       "      <td>0.399619</td>\n",
       "      <td>0.571019</td>\n",
       "      <td>0.326200</td>\n",
       "      <td>0.598230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185626</td>\n",
       "      <td>0.528407</td>\n",
       "      <td>0.147522</td>\n",
       "      <td>0.439869</td>\n",
       "      <td>0.350594</td>\n",
       "      <td>0.240671</td>\n",
       "      <td>0.090573</td>\n",
       "      <td>0.077962</td>\n",
       "      <td>77.050000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930</td>\n",
       "      <td>18.902453</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>18.709255</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>22.614889</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  284315.000000  284315.000000  284315.000000  284315.000000   \n",
       "mean    94838.202258       0.008258      -0.006271       0.012171   \n",
       "std     47484.015786       1.929814       1.636146       1.459429   \n",
       "min         0.000000     -56.407510     -72.715728     -48.325589   \n",
       "25%     54230.000000      -0.917544      -0.599473      -0.884541   \n",
       "50%     84711.000000       0.020023       0.064070       0.182158   \n",
       "75%    139333.000000       1.316218       0.800446       1.028372   \n",
       "max    172792.000000       2.454930      18.902453       9.382558   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  284315.000000  284315.000000  284315.000000  284315.000000   \n",
       "mean       -0.007860       0.005453       0.002419       0.009637   \n",
       "std         1.399333       1.356952       1.329913       1.178812   \n",
       "min        -5.683171    -113.743307     -26.160506     -31.764946   \n",
       "25%        -0.850077      -0.689398      -0.766847      -0.551442   \n",
       "50%        -0.022405      -0.053457      -0.273123       0.041138   \n",
       "75%         0.737624       0.612181       0.399619       0.571019   \n",
       "max        16.875344      34.801666      73.301626     120.589494   \n",
       "\n",
       "                  V8             V9    ...               V21            V22  \\\n",
       "count  284315.000000  284315.000000    ...     284315.000000  284315.000000   \n",
       "mean       -0.000987       0.004467    ...         -0.001235      -0.000024   \n",
       "std         1.161283       1.089372    ...          0.716743       0.723668   \n",
       "min       -73.216718      -6.290730    ...        -34.830382     -10.933144   \n",
       "25%        -0.208633      -0.640412    ...         -0.228509      -0.542403   \n",
       "50%         0.022041      -0.049964    ...         -0.029821       0.006736   \n",
       "75%         0.326200       0.598230    ...          0.185626       0.528407   \n",
       "max        18.709255      15.594995    ...         22.614889      10.503090   \n",
       "\n",
       "                 V23            V24            V25            V26  \\\n",
       "count  284315.000000  284315.000000  284315.000000  284315.000000   \n",
       "mean        0.000070       0.000182      -0.000072      -0.000089   \n",
       "std         0.621541       0.605776       0.520673       0.482241   \n",
       "min       -44.807735      -2.836627     -10.295397      -2.604551   \n",
       "25%        -0.161702      -0.354425      -0.317145      -0.327074   \n",
       "50%        -0.011147       0.041082       0.016417      -0.052227   \n",
       "75%         0.147522       0.439869       0.350594       0.240671   \n",
       "max        22.528412       4.584549       7.519589       3.517346   \n",
       "\n",
       "                 V27            V28         Amount     Class  \n",
       "count  284315.000000  284315.000000  284315.000000  284315.0  \n",
       "mean       -0.000295      -0.000131      88.291022       0.0  \n",
       "std         0.399847       0.329570     250.105092       0.0  \n",
       "min       -22.565679     -15.430084       0.000000       0.0  \n",
       "25%        -0.070852      -0.052950       5.650000       0.0  \n",
       "50%         0.001230       0.011199      22.000000       0.0  \n",
       "75%         0.090573       0.077962      77.050000       0.0  \n",
       "max        31.612198      33.847808   25691.160000       0.0  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Class'] == 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time      2.255124e+09\n",
      "V1        3.836489e+00\n",
      "V2        2.726820e+00\n",
      "V3        2.299029e+00\n",
      "V4        2.004684e+00\n",
      "V5        1.905081e+00\n",
      "V6        1.774946e+00\n",
      "V7        1.530401e+00\n",
      "V8        1.426479e+00\n",
      "V9        1.206992e+00\n",
      "V10       1.185594e+00\n",
      "V11       1.041855e+00\n",
      "V12       9.984034e-01\n",
      "V13       9.905708e-01\n",
      "V14       9.189055e-01\n",
      "V15       8.378034e-01\n",
      "V16       7.678191e-01\n",
      "V17       7.213734e-01\n",
      "V18       7.025394e-01\n",
      "V19       6.626619e-01\n",
      "V20       5.943254e-01\n",
      "V21       5.395255e-01\n",
      "V22       5.266428e-01\n",
      "V23       3.899507e-01\n",
      "V24       3.668084e-01\n",
      "V25       2.717308e-01\n",
      "V26       2.325429e-01\n",
      "V27       1.629192e-01\n",
      "V28       1.089550e-01\n",
      "Amount    6.256007e+04\n",
      "Class     1.724507e-03\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Variance check before Featue scaling \n",
    "print(df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10cea2cc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Correlation check before Feature Scaling\n",
    "df.corrwith(df.Class).plot.bar(\n",
    "        figsize = (20, 10), title = 'Correlation with Class before Amount scaling', fontsize = 20,\n",
    "        rot = 45, grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot of fraudulent and non-fraudulent\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "ax[0].scatter(df['Time'][df['Class'] == 0], df['Amount'][df['Class']==0], color='b' )\n",
    "ax[0].scatter(df['Time'][df['Class'] == 1], df['Amount'][df['Class']==1], color='r' , marker='.')\n",
    "ax[0].legend(['non fraudulent', 'fraudulent'], loc='best')\n",
    "ax[1].hist( df['Amount'][df['Class']==0], 100, facecolor='b', alpha=0.5, label=\"Distribution of amounts for non-fraudulent \")\n",
    "ax[2].hist( df['Amount'][df['Class']==1], 100, facecolor='r', ec=\"black\", lw=0.5, alpha=0.5, label=\"Distribution of amounts for fraudulent\")\n",
    "ax[0].set_xlabel('Time')\n",
    "ax[0].set_ylabel('Amount')\n",
    "ax[1].set_xlabel('Amount')\n",
    "ax[1].set_ylabel('Frequency')\n",
    "ax[2].set_xlabel('Amount')\n",
    "ax[2].set_ylabel('Frequency')\n",
    "ax[1].set_title('non-fraudulent')\n",
    "ax[2].set_title('fraudulent')\n",
    "fig.subplots_adjust(left=0, right=2, bottom=0, top=1, hspace=0.05, wspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n",
      "0    0.998273\n",
      "1    0.001727\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of fraud and no fraud and print them\n",
    "occ = df['Class'].value_counts()\n",
    "print(occ)\n",
    "\n",
    "# Print the ratio of fraud cases\n",
    "print(occ / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class Distributions \\n (0: No Fraud || 1: Fraud)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "sns.countplot('Class', data=df, palette=colors)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a3e286320>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Fraud_transacation = df[df['Class']==1]\n",
    "Normal_transacation= df[df['Class']==0]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "Fraud_transacation.Amount.plot.hist(title=\"Fraud Transacation\")\n",
    "plt.subplot(122)\n",
    "Normal_transacation.Amount.plot.hist(title=\"Normal Transaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11c33d080>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the distribution for Normal transction is not clear and it seams that all transaction are less than 2.5 K\n",
    "# So plot graph for same \n",
    "Fraud_transacation = df[df[\"Class\"]==1]\n",
    "Normal_transacation= df[df[\"Class\"]==0]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "Fraud_transacation[Fraud_transacation[\"Amount\"]<= 2500].Amount.plot.hist(title=\"Fraud Tranascation\")\n",
    "plt.subplot(122)\n",
    "Normal_transacation[Normal_transacation[\"Amount\"]<=2500].Amount.plot.hist(title=\"Normal Transaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...         V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...   -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ...   -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...    0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ...   -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...   -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28    Amount  Class  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  0.244964      0  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724 -0.342475      0  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  1.160686      0  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  0.140534      0  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153 -0.073403      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Amount scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "df['Amount'] = ss.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df.drop(['Time'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10da4df28>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Correlation check after feature scaling\n",
    "df.corrwith(df.Class).plot.bar(\n",
    "        figsize = (20, 10), title = \"Correlation with Class after amount scaling\", fontsize = 20,\n",
    "        rot = 45, grid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1        3.836489\n",
      "V2        2.726820\n",
      "V3        2.299029\n",
      "V4        2.004684\n",
      "V5        1.905081\n",
      "V6        1.774946\n",
      "V7        1.530401\n",
      "V8        1.426479\n",
      "V9        1.206992\n",
      "V10       1.185594\n",
      "V11       1.041855\n",
      "V12       0.998403\n",
      "V13       0.990571\n",
      "V14       0.918906\n",
      "V15       0.837803\n",
      "V16       0.767819\n",
      "V17       0.721373\n",
      "V18       0.702539\n",
      "V19       0.662662\n",
      "V20       0.594325\n",
      "V21       0.539526\n",
      "V22       0.526643\n",
      "V23       0.389951\n",
      "V24       0.366808\n",
      "V25       0.271731\n",
      "V26       0.232543\n",
      "V27       0.162919\n",
      "V28       0.108955\n",
      "Amount    1.000004\n",
      "Class     0.001725\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Variance check after feature scaling\n",
    "print(df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'Class' ]\n",
    "Y = df.loc[:, df.columns == 'Class' ]\n",
    "\n",
    "#Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, \n",
    "                                                    stratify = Y)\n",
    "\n",
    "X_train_train, X_test_test, Y_train_train, Y_test_test = train_test_split(X_train, Y_train, test_size = 0.20)\n",
    "\n",
    "sm = SMOTE(random_state=42, kind = 'borderline1')\n",
    "\n",
    "X_resampled, Y_resampled = sm.fit_resample(X_train_train, Y_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to determine layers, batch size, activation and epochs\n",
    "# def create_model(layers, activation):\n",
    "#     model = Sequential()\n",
    "#     for i, nodes in enumerate(layers):\n",
    "#         if i == 0:\n",
    "#             model.add(Dense(nodes, input_dim = len(X.columns)))\n",
    "#             model.add(Activation(activation))\n",
    "#         else:\n",
    "#             model.add(Dense(nodes))\n",
    "#             model.add(Activation(activation))\n",
    "#     model.add(Dense(1))\n",
    "    \n",
    "#     model.compile(optimizer = 'adam', loss='binary_crossentropy')\n",
    "#     return(model)\n",
    "\n",
    "# model = KerasClassifier(build_fn = create_model, verbose = 1)\n",
    "\n",
    "# layers = [[29], [30], [35], [40], [45], [50], [60], [65], [70]]\n",
    "# activations = [keras.activations.sigmoid, keras.activations.relu]\n",
    "# param_grid = dict(layers = layers, activation = activations, batch_size = [256, 512], epochs = [30])\n",
    "# grid = GridSearchCV(estimator = model, param_grid = param_grid, scoring= 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to determine neurons, dropout rate and kernel intializer\n",
    "# def create_model(neurons=1, dropout_rate=0.0, init_mode='uniform'):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(neurons, input_dim=len(X.columns), kernel_initializer=init_mode, activation='relu'))\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "#     model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    \n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "#     return model\n",
    "# model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=256, verbose=1)\n",
    "# neurons = [29, 30, 35, 40, 45, 50, 55, 60, 65, 70]\n",
    "# dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "# param_grid = dict(neurons = neurons, dropout_rate=dropout_rate, init_mode=init_mode)\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=5, scoring = make_scorer(f1_score))\n",
    "# grid_result = grid.fit(X_resampled, Y_resampled)\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to determine important features in the dataset\n",
    "# def base_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(64, input_dim=len(X.columns), activation='relu'))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# my_model = KerasClassifier(build_fn=base_model)    \n",
    "# my_model.fit(X_resampled,Y_resampled)\n",
    "\n",
    "# perm = PermutationImportance(my_model, random_state=42).fit(X_resampled,Y_resampled)\n",
    "# eli5.show_weights(perm, feature_names = X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to determine Learning Rate \n",
    "# model = Sequential()\n",
    "# model.add(Dense(64, input_dim=len(X.columns), activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# from keras_lr_finder import LRFinder\n",
    "# lr_finder = LRFinder(model)\n",
    "# lr_finder.find(X_resampled, Y_resampled, .00001, 1, 512, 5)\n",
    "\n",
    "# lr_finder.plot_loss()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.1191 - acc: 0.9586 - val_loss: 0.0278 - val_acc: 0.9918\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0279 - acc: 0.9925 - val_loss: 0.0179 - val_acc: 0.9947\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0190 - acc: 0.9952 - val_loss: 0.0147 - val_acc: 0.9961\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0147 - acc: 0.9967 - val_loss: 0.0131 - val_acc: 0.9968\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0119 - acc: 0.9975 - val_loss: 0.0111 - val_acc: 0.9974\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0105 - acc: 0.9979 - val_loss: 0.0105 - val_acc: 0.9979\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0093 - acc: 0.9983 - val_loss: 0.0096 - val_acc: 0.9982\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0087 - acc: 0.9984 - val_loss: 0.0094 - val_acc: 0.9983\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.0091 - val_acc: 0.9986\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0070 - acc: 0.9988 - val_loss: 0.0087 - val_acc: 0.9987\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0064 - acc: 0.9990 - val_loss: 0.0086 - val_acc: 0.9988\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0087 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0056 - acc: 0.9992 - val_loss: 0.0086 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.1415 - acc: 0.9476 - val_loss: 0.0308 - val_acc: 0.9908\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0284 - acc: 0.9926 - val_loss: 0.0200 - val_acc: 0.9943\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0192 - acc: 0.9952 - val_loss: 0.0147 - val_acc: 0.9961\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0148 - acc: 0.9967 - val_loss: 0.0133 - val_acc: 0.9967\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0126 - acc: 0.9973 - val_loss: 0.0116 - val_acc: 0.9974\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0104 - acc: 0.9978 - val_loss: 0.0115 - val_acc: 0.9975\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0096 - acc: 0.9982 - val_loss: 0.0110 - val_acc: 0.9978\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0083 - acc: 0.9985 - val_loss: 0.0107 - val_acc: 0.9980\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0076 - acc: 0.9987 - val_loss: 0.0101 - val_acc: 0.9982\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0070 - acc: 0.9988 - val_loss: 0.0094 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0064 - acc: 0.9990 - val_loss: 0.0095 - val_acc: 0.9985\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0061 - acc: 0.9990 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0057 - acc: 0.9991 - val_loss: 0.0091 - val_acc: 0.9987\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0094 - val_acc: 0.9987\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.1300 - acc: 0.9516 - val_loss: 0.0252 - val_acc: 0.9928\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0251 - acc: 0.9932 - val_loss: 0.0165 - val_acc: 0.9954\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0172 - acc: 0.9957 - val_loss: 0.0138 - val_acc: 0.9965\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0134 - acc: 0.9970 - val_loss: 0.0125 - val_acc: 0.9970\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0113 - acc: 0.9977 - val_loss: 0.0120 - val_acc: 0.9972\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0096 - acc: 0.9981 - val_loss: 0.0107 - val_acc: 0.9978\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0088 - acc: 0.9984 - val_loss: 0.0091 - val_acc: 0.9985\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.0093 - val_acc: 0.9985\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0070 - acc: 0.9989 - val_loss: 0.0091 - val_acc: 0.9986\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.1336 - acc: 0.9532 - val_loss: 0.0284 - val_acc: 0.9913\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0283 - acc: 0.9922 - val_loss: 0.0179 - val_acc: 0.9947\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0193 - acc: 0.9950 - val_loss: 0.0144 - val_acc: 0.9962\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0149 - acc: 0.9965 - val_loss: 0.0132 - val_acc: 0.9966\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0127 - acc: 0.9973 - val_loss: 0.0117 - val_acc: 0.9973\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0105 - acc: 0.9979 - val_loss: 0.0099 - val_acc: 0.9981\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0092 - acc: 0.9982 - val_loss: 0.0097 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0083 - acc: 0.9985 - val_loss: 0.0092 - val_acc: 0.9984\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0072 - acc: 0.9988 - val_loss: 0.0089 - val_acc: 0.9985\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0070 - acc: 0.9988 - val_loss: 0.0089 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0089 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0086 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0056 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9988\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0052 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.1372 - acc: 0.9535 - val_loss: 0.0298 - val_acc: 0.9910\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0288 - acc: 0.9921 - val_loss: 0.0185 - val_acc: 0.9945\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0196 - acc: 0.9950 - val_loss: 0.0159 - val_acc: 0.9956\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0148 - acc: 0.9967 - val_loss: 0.0127 - val_acc: 0.9969\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0124 - acc: 0.9974 - val_loss: 0.0115 - val_acc: 0.9973\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0109 - val_acc: 0.9978\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0094 - acc: 0.9983 - val_loss: 0.0097 - val_acc: 0.9983\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0085 - acc: 0.9985 - val_loss: 0.0102 - val_acc: 0.9983\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0072 - acc: 0.9988 - val_loss: 0.0087 - val_acc: 0.9987\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0070 - acc: 0.9989 - val_loss: 0.0089 - val_acc: 0.9987\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0087 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0059 - acc: 0.9992 - val_loss: 0.0083 - val_acc: 0.9989\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0055 - acc: 0.9992 - val_loss: 0.0085 - val_acc: 0.9988\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0084 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.1493 - acc: 0.9458 - val_loss: 0.0313 - val_acc: 0.9908\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0299 - acc: 0.9919 - val_loss: 0.0196 - val_acc: 0.9944\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0203 - acc: 0.9948 - val_loss: 0.0153 - val_acc: 0.9958\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0161 - acc: 0.9961 - val_loss: 0.0133 - val_acc: 0.9967\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0131 - acc: 0.9971 - val_loss: 0.0124 - val_acc: 0.9971\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0110 - acc: 0.9977 - val_loss: 0.0107 - val_acc: 0.9976\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0095 - acc: 0.9982 - val_loss: 0.0105 - val_acc: 0.9979\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0086 - acc: 0.9984 - val_loss: 0.0105 - val_acc: 0.9980\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0077 - acc: 0.9986 - val_loss: 0.0096 - val_acc: 0.9984\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0071 - acc: 0.9988 - val_loss: 0.0093 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0064 - acc: 0.9990 - val_loss: 0.0092 - val_acc: 0.9986\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0062 - acc: 0.9990 - val_loss: 0.0091 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0057 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9988\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0087 - val_acc: 0.9989\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0087 - val_acc: 0.9989\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0047 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.1553 - acc: 0.9477 - val_loss: 0.0303 - val_acc: 0.9916\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0308 - acc: 0.9918 - val_loss: 0.0191 - val_acc: 0.9944\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0203 - acc: 0.9948 - val_loss: 0.0151 - val_acc: 0.9960\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0162 - acc: 0.9964 - val_loss: 0.0131 - val_acc: 0.9968\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0134 - acc: 0.9972 - val_loss: 0.0118 - val_acc: 0.9973\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0111 - acc: 0.9977 - val_loss: 0.0109 - val_acc: 0.9977\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0100 - acc: 0.9981 - val_loss: 0.0094 - val_acc: 0.9983\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0087 - acc: 0.9984 - val_loss: 0.0105 - val_acc: 0.9980\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0080 - acc: 0.9987 - val_loss: 0.0094 - val_acc: 0.9985\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0085 - val_acc: 0.9987\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0068 - acc: 0.9989 - val_loss: 0.0087 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0063 - acc: 0.9991 - val_loss: 0.0092 - val_acc: 0.9987\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.1474 - acc: 0.9499 - val_loss: 0.0278 - val_acc: 0.9917\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0301 - acc: 0.9920 - val_loss: 0.0187 - val_acc: 0.9944\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0199 - acc: 0.9950 - val_loss: 0.0144 - val_acc: 0.9960\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0152 - acc: 0.9967 - val_loss: 0.0120 - val_acc: 0.9971\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0127 - acc: 0.9974 - val_loss: 0.0114 - val_acc: 0.9976\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0108 - acc: 0.9979 - val_loss: 0.0111 - val_acc: 0.9977\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0096 - acc: 0.9983 - val_loss: 0.0102 - val_acc: 0.9982\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0082 - acc: 0.9985 - val_loss: 0.0093 - val_acc: 0.9984\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0072 - acc: 0.9988 - val_loss: 0.0092 - val_acc: 0.9985\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0069 - acc: 0.9989 - val_loss: 0.0089 - val_acc: 0.9987\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0087 - val_acc: 0.9988\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0057 - acc: 0.9992 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0051 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.1350 - acc: 0.9518 - val_loss: 0.0284 - val_acc: 0.9916\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0287 - acc: 0.9923 - val_loss: 0.0194 - val_acc: 0.9944\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0190 - acc: 0.9953 - val_loss: 0.0161 - val_acc: 0.9956\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0146 - acc: 0.9968 - val_loss: 0.0124 - val_acc: 0.9969\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0117 - acc: 0.9976 - val_loss: 0.0110 - val_acc: 0.9975\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0102 - acc: 0.9981 - val_loss: 0.0100 - val_acc: 0.9980\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0089 - acc: 0.9984 - val_loss: 0.0096 - val_acc: 0.9983\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0078 - acc: 0.9986 - val_loss: 0.0092 - val_acc: 0.9986\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0071 - acc: 0.9988 - val_loss: 0.0092 - val_acc: 0.9986\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0067 - acc: 0.9989 - val_loss: 0.0091 - val_acc: 0.9987\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0061 - acc: 0.9990 - val_loss: 0.0088 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0055 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0053 - acc: 0.9993 - val_loss: 0.0090 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 16us/step - loss: 0.1283 - acc: 0.9519 - val_loss: 0.0264 - val_acc: 0.9914\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0245 - acc: 0.9939 - val_loss: 0.0167 - val_acc: 0.9952\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0169 - acc: 0.9960 - val_loss: 0.0132 - val_acc: 0.9965\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0133 - acc: 0.9972 - val_loss: 0.0119 - val_acc: 0.9970\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0114 - acc: 0.9977 - val_loss: 0.0108 - val_acc: 0.9975\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0098 - acc: 0.9981 - val_loss: 0.0109 - val_acc: 0.9976\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0086 - acc: 0.9983 - val_loss: 0.0096 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0081 - acc: 0.9986 - val_loss: 0.0098 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0072 - acc: 0.9988 - val_loss: 0.0090 - val_acc: 0.9986\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0067 - acc: 0.9990 - val_loss: 0.0090 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0085 - val_acc: 0.9988\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0052 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.2054 - acc: 0.9351 - val_loss: 0.0330 - val_acc: 0.9904\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0339 - acc: 0.9907 - val_loss: 0.0193 - val_acc: 0.9944\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0225 - acc: 0.9943 - val_loss: 0.0159 - val_acc: 0.9957\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0174 - acc: 0.9961 - val_loss: 0.0141 - val_acc: 0.9965\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0143 - acc: 0.9969 - val_loss: 0.0119 - val_acc: 0.9970\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0119 - acc: 0.9976 - val_loss: 0.0128 - val_acc: 0.9969\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0107 - acc: 0.9980 - val_loss: 0.0107 - val_acc: 0.9978\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0093 - acc: 0.9982 - val_loss: 0.0103 - val_acc: 0.9980\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0084 - acc: 0.9985 - val_loss: 0.0097 - val_acc: 0.9984\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.0097 - val_acc: 0.9985\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0069 - acc: 0.9989 - val_loss: 0.0097 - val_acc: 0.9985\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.1166 - acc: 0.9583 - val_loss: 0.0268 - val_acc: 0.9919\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0251 - acc: 0.9936 - val_loss: 0.0162 - val_acc: 0.9953\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0171 - acc: 0.9960 - val_loss: 0.0134 - val_acc: 0.9968\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0131 - acc: 0.9974 - val_loss: 0.0122 - val_acc: 0.9971\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0108 - acc: 0.9979 - val_loss: 0.0103 - val_acc: 0.9980\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0093 - acc: 0.9983 - val_loss: 0.0100 - val_acc: 0.9981\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0083 - acc: 0.9985 - val_loss: 0.0095 - val_acc: 0.9984\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0076 - acc: 0.9987 - val_loss: 0.0094 - val_acc: 0.9985\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0071 - acc: 0.9988 - val_loss: 0.0093 - val_acc: 0.9986\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0087 - val_acc: 0.9988\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0057 - acc: 0.9991 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0056 - acc: 0.9992 - val_loss: 0.0084 - val_acc: 0.9989\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9989\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 5s 15us/step - loss: 0.0048 - acc: 0.9993 - val_loss: 0.0084 - val_acc: 0.9990\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0084 - val_acc: 0.9990\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0045 - acc: 0.9994 - val_loss: 0.0084 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 15us/step - loss: 0.1546 - acc: 0.9442 - val_loss: 0.0315 - val_acc: 0.9903\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0293 - acc: 0.9924 - val_loss: 0.0204 - val_acc: 0.9942\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0197 - acc: 0.9952 - val_loss: 0.0161 - val_acc: 0.9956\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0154 - acc: 0.9965 - val_loss: 0.0130 - val_acc: 0.9968\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0125 - acc: 0.9975 - val_loss: 0.0127 - val_acc: 0.9969\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0110 - acc: 0.9978 - val_loss: 0.0112 - val_acc: 0.9975\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0094 - acc: 0.9981 - val_loss: 0.0103 - val_acc: 0.9980\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0085 - acc: 0.9985 - val_loss: 0.0100 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0092 - val_acc: 0.9985\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0069 - acc: 0.9988 - val_loss: 0.0091 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0063 - acc: 0.9989 - val_loss: 0.0095 - val_acc: 0.9985\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0085 - val_acc: 0.9988\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9988\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0090 - val_acc: 0.9988\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 15us/step - loss: 0.1381 - acc: 0.9534 - val_loss: 0.0316 - val_acc: 0.9908\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0295 - acc: 0.9925 - val_loss: 0.0196 - val_acc: 0.9943\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0197 - acc: 0.9953 - val_loss: 0.0163 - val_acc: 0.9953\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0152 - acc: 0.9967 - val_loss: 0.0140 - val_acc: 0.9965\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0125 - acc: 0.9975 - val_loss: 0.0112 - val_acc: 0.9974\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0105 - acc: 0.9980 - val_loss: 0.0104 - val_acc: 0.9978\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0093 - acc: 0.9984 - val_loss: 0.0102 - val_acc: 0.9980\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0084 - acc: 0.9986 - val_loss: 0.0097 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0073 - acc: 0.9989 - val_loss: 0.0095 - val_acc: 0.9984\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.0096 - val_acc: 0.9984\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0063 - acc: 0.9991 - val_loss: 0.0089 - val_acc: 0.9988\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0059 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9988\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9989\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0048 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9989\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0083 - val_acc: 0.9990\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0041 - acc: 0.9995 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 16us/step - loss: 0.1759 - acc: 0.9406 - val_loss: 0.0325 - val_acc: 0.9912\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0328 - acc: 0.9912 - val_loss: 0.0203 - val_acc: 0.9944\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0216 - acc: 0.9946 - val_loss: 0.0160 - val_acc: 0.9955\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0166 - acc: 0.9961 - val_loss: 0.0137 - val_acc: 0.9967\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0137 - acc: 0.9971 - val_loss: 0.0117 - val_acc: 0.9975\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0112 - acc: 0.9978 - val_loss: 0.0108 - val_acc: 0.9978\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0098 - acc: 0.9981 - val_loss: 0.0104 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0090 - acc: 0.9984 - val_loss: 0.0103 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0079 - acc: 0.9986 - val_loss: 0.0094 - val_acc: 0.9985\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0074 - acc: 0.9988 - val_loss: 0.0091 - val_acc: 0.9985\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0069 - acc: 0.9989 - val_loss: 0.0092 - val_acc: 0.9986\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0094 - val_acc: 0.9986\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 16us/step - loss: 0.1561 - acc: 0.9458 - val_loss: 0.0324 - val_acc: 0.9914\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0309 - acc: 0.9917 - val_loss: 0.0191 - val_acc: 0.9948\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0208 - acc: 0.9947 - val_loss: 0.0153 - val_acc: 0.9959\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0160 - acc: 0.9963 - val_loss: 0.0127 - val_acc: 0.9969\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0131 - acc: 0.9972 - val_loss: 0.0120 - val_acc: 0.9971\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0112 - acc: 0.9977 - val_loss: 0.0113 - val_acc: 0.9976\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0100 - acc: 0.9981 - val_loss: 0.0102 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0087 - acc: 0.9985 - val_loss: 0.0105 - val_acc: 0.9980\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0081 - acc: 0.9986 - val_loss: 0.0100 - val_acc: 0.9983\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0073 - acc: 0.9987 - val_loss: 0.0096 - val_acc: 0.9985\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0069 - acc: 0.9989 - val_loss: 0.0097 - val_acc: 0.9986\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0063 - acc: 0.9991 - val_loss: 0.0093 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0093 - val_acc: 0.9987\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0090 - val_acc: 0.9988\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0052 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9989\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0090 - val_acc: 0.9989\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0045 - acc: 0.9994 - val_loss: 0.0089 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 17us/step - loss: 0.1279 - acc: 0.9535 - val_loss: 0.0265 - val_acc: 0.9928\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0280 - acc: 0.9929 - val_loss: 0.0185 - val_acc: 0.9950\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0188 - acc: 0.9956 - val_loss: 0.0153 - val_acc: 0.9960\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0147 - acc: 0.9968 - val_loss: 0.0127 - val_acc: 0.9969\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0124 - acc: 0.9974 - val_loss: 0.0119 - val_acc: 0.9972\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0108 - acc: 0.9979 - val_loss: 0.0111 - val_acc: 0.9977\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0094 - acc: 0.9982 - val_loss: 0.0104 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0083 - acc: 0.9985 - val_loss: 0.0096 - val_acc: 0.9984\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0095 - val_acc: 0.9985\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0070 - acc: 0.9989 - val_loss: 0.0092 - val_acc: 0.9987\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0092 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9989\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0091 - val_acc: 0.9989\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0089 - val_acc: 0.9989\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0086 - val_acc: 0.9989\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0045 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0043 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 20/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0041 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "Epoch 21/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0039 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9991\n",
      "Epoch 22/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0040 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9991\n",
      "Epoch 23/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0037 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 16us/step - loss: 0.1810 - acc: 0.9342 - val_loss: 0.0389 - val_acc: 0.9893\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0358 - acc: 0.9902 - val_loss: 0.0224 - val_acc: 0.9937\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0225 - acc: 0.9944 - val_loss: 0.0167 - val_acc: 0.9956\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0168 - acc: 0.9962 - val_loss: 0.0142 - val_acc: 0.9968\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0137 - acc: 0.9972 - val_loss: 0.0130 - val_acc: 0.9972\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0114 - acc: 0.9978 - val_loss: 0.0113 - val_acc: 0.9976\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0103 - acc: 0.9981 - val_loss: 0.0107 - val_acc: 0.9978\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0093 - acc: 0.9984 - val_loss: 0.0101 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0085 - acc: 0.9986 - val_loss: 0.0097 - val_acc: 0.9983\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0076 - acc: 0.9989 - val_loss: 0.0099 - val_acc: 0.9984\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0070 - acc: 0.9989 - val_loss: 0.0095 - val_acc: 0.9986\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0066 - acc: 0.9990 - val_loss: 0.0094 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0095 - val_acc: 0.9987\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0093 - val_acc: 0.9988\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0052 - acc: 0.9992 - val_loss: 0.0093 - val_acc: 0.9989\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0094 - val_acc: 0.9988\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0092 - val_acc: 0.9989\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0045 - acc: 0.9994 - val_loss: 0.0089 - val_acc: 0.9989\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0091 - val_acc: 0.9989\n",
      "Epoch 20/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0042 - acc: 0.9994 - val_loss: 0.0091 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.1704 - acc: 0.9412 - val_loss: 0.0308 - val_acc: 0.9915\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0323 - acc: 0.9915 - val_loss: 0.0204 - val_acc: 0.9944\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0216 - acc: 0.9946 - val_loss: 0.0157 - val_acc: 0.9959\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0161 - acc: 0.9963 - val_loss: 0.0147 - val_acc: 0.9963\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0132 - acc: 0.9973 - val_loss: 0.0126 - val_acc: 0.9971\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0115 - acc: 0.9977 - val_loss: 0.0113 - val_acc: 0.9976\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0100 - acc: 0.9981 - val_loss: 0.0107 - val_acc: 0.9978\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0088 - acc: 0.9984 - val_loss: 0.0097 - val_acc: 0.9984\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0084 - acc: 0.9986 - val_loss: 0.0099 - val_acc: 0.9984\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0074 - acc: 0.9987 - val_loss: 0.0095 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0070 - acc: 0.9988 - val_loss: 0.0094 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0065 - acc: 0.9990 - val_loss: 0.0095 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0088 - val_acc: 0.9988\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0057 - acc: 0.9992 - val_loss: 0.0090 - val_acc: 0.9988\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0052 - acc: 0.9993 - val_loss: 0.0092 - val_acc: 0.9988\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 16us/step - loss: 0.1485 - acc: 0.9439 - val_loss: 0.0316 - val_acc: 0.9908\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0303 - acc: 0.9923 - val_loss: 0.0181 - val_acc: 0.9949\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0196 - acc: 0.9954 - val_loss: 0.0144 - val_acc: 0.9962\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0150 - acc: 0.9969 - val_loss: 0.0126 - val_acc: 0.9969\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0124 - acc: 0.9975 - val_loss: 0.0115 - val_acc: 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0106 - acc: 0.9980 - val_loss: 0.0102 - val_acc: 0.9979\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0093 - acc: 0.9983 - val_loss: 0.0106 - val_acc: 0.9979\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0084 - acc: 0.9985 - val_loss: 0.0092 - val_acc: 0.9985\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.0091 - val_acc: 0.9986\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0071 - acc: 0.9988 - val_loss: 0.0092 - val_acc: 0.9987\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0064 - acc: 0.9990 - val_loss: 0.0092 - val_acc: 0.9987\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 17us/step - loss: 0.1531 - acc: 0.9467 - val_loss: 0.0309 - val_acc: 0.9913\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0301 - acc: 0.9917 - val_loss: 0.0188 - val_acc: 0.9944\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0201 - acc: 0.9949 - val_loss: 0.0165 - val_acc: 0.9953\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0155 - acc: 0.9965 - val_loss: 0.0127 - val_acc: 0.9970\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0126 - acc: 0.9974 - val_loss: 0.0115 - val_acc: 0.9973\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0111 - acc: 0.9978 - val_loss: 0.0110 - val_acc: 0.9977\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0096 - acc: 0.9982 - val_loss: 0.0108 - val_acc: 0.9978\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0086 - acc: 0.9984 - val_loss: 0.0102 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0079 - acc: 0.9986 - val_loss: 0.0097 - val_acc: 0.9984\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0072 - acc: 0.9988 - val_loss: 0.0089 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0067 - acc: 0.9989 - val_loss: 0.0089 - val_acc: 0.9986\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0064 - acc: 0.9989 - val_loss: 0.0091 - val_acc: 0.9986\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0084 - val_acc: 0.9988\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0057 - acc: 0.9991 - val_loss: 0.0086 - val_acc: 0.9988\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0051 - acc: 0.9992 - val_loss: 0.0086 - val_acc: 0.9988\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 17us/step - loss: 0.1474 - acc: 0.9464 - val_loss: 0.0297 - val_acc: 0.9904\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0294 - acc: 0.9922 - val_loss: 0.0197 - val_acc: 0.9940\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0195 - acc: 0.9951 - val_loss: 0.0143 - val_acc: 0.9962\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0148 - acc: 0.9966 - val_loss: 0.0125 - val_acc: 0.9969\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.0117 - val_acc: 0.9974\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0103 - acc: 0.9979 - val_loss: 0.0101 - val_acc: 0.9979\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0094 - acc: 0.9982 - val_loss: 0.0097 - val_acc: 0.9982\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0080 - acc: 0.9986 - val_loss: 0.0092 - val_acc: 0.9984\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0073 - acc: 0.9987 - val_loss: 0.0086 - val_acc: 0.9987\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0068 - acc: 0.9989 - val_loss: 0.0096 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0085 - val_acc: 0.9988\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0087 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0054 - acc: 0.9991 - val_loss: 0.0086 - val_acc: 0.9988\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 16us/step - loss: 0.1968 - acc: 0.9292 - val_loss: 0.0352 - val_acc: 0.9901\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0350 - acc: 0.9905 - val_loss: 0.0216 - val_acc: 0.9941\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0232 - acc: 0.9940 - val_loss: 0.0168 - val_acc: 0.9952\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0178 - acc: 0.9958 - val_loss: 0.0140 - val_acc: 0.9964\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0148 - acc: 0.9966 - val_loss: 0.0136 - val_acc: 0.9965\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0126 - acc: 0.9973 - val_loss: 0.0123 - val_acc: 0.9970\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0108 - acc: 0.9978 - val_loss: 0.0114 - val_acc: 0.9975\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0098 - acc: 0.9981 - val_loss: 0.0099 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0091 - acc: 0.9983 - val_loss: 0.0100 - val_acc: 0.9983\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0081 - acc: 0.9985 - val_loss: 0.0096 - val_acc: 0.9983\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 10us/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0093 - val_acc: 0.9985\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0069 - acc: 0.9989 - val_loss: 0.0094 - val_acc: 0.9985\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0065 - acc: 0.9989 - val_loss: 0.0094 - val_acc: 0.9987\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 17us/step - loss: 0.2000 - acc: 0.9311 - val_loss: 0.0328 - val_acc: 0.9912\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0343 - acc: 0.9904 - val_loss: 0.0194 - val_acc: 0.9943\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0226 - acc: 0.9942 - val_loss: 0.0168 - val_acc: 0.9953\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0176 - acc: 0.9958 - val_loss: 0.0134 - val_acc: 0.9966\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0144 - acc: 0.9968 - val_loss: 0.0131 - val_acc: 0.9967\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0123 - acc: 0.9974 - val_loss: 0.0121 - val_acc: 0.9973\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0107 - acc: 0.9979 - val_loss: 0.0112 - val_acc: 0.9977\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0094 - acc: 0.9983 - val_loss: 0.0102 - val_acc: 0.9981\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0084 - acc: 0.9986 - val_loss: 0.0102 - val_acc: 0.9981\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0096 - val_acc: 0.9983\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0072 - acc: 0.9988 - val_loss: 0.0089 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0094 - val_acc: 0.9986\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0057 - acc: 0.9992 - val_loss: 0.0095 - val_acc: 0.9986\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 16us/step - loss: 0.1184 - acc: 0.9576 - val_loss: 0.0273 - val_acc: 0.9926\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0265 - acc: 0.9931 - val_loss: 0.0179 - val_acc: 0.9952\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0178 - acc: 0.9958 - val_loss: 0.0149 - val_acc: 0.9961\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0136 - acc: 0.9969 - val_loss: 0.0121 - val_acc: 0.9971\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0112 - acc: 0.9976 - val_loss: 0.0108 - val_acc: 0.9975\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0097 - acc: 0.9981 - val_loss: 0.0107 - val_acc: 0.9978\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0087 - acc: 0.9983 - val_loss: 0.0097 - val_acc: 0.9983\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0078 - acc: 0.9986 - val_loss: 0.0094 - val_acc: 0.9984\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0069 - acc: 0.9989 - val_loss: 0.0095 - val_acc: 0.9985\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0065 - acc: 0.9990 - val_loss: 0.0089 - val_acc: 0.9987\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0061 - acc: 0.9991 - val_loss: 0.0089 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0055 - acc: 0.9992 - val_loss: 0.0090 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0086 - val_acc: 0.9989\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0092 - val_acc: 0.9988\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0089 - val_acc: 0.9989\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 16us/step - loss: 0.2032 - acc: 0.9308 - val_loss: 0.0347 - val_acc: 0.9897\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0340 - acc: 0.9906 - val_loss: 0.0203 - val_acc: 0.9939\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0217 - acc: 0.9945 - val_loss: 0.0166 - val_acc: 0.9953\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0171 - acc: 0.9960 - val_loss: 0.0144 - val_acc: 0.9964\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0142 - acc: 0.9968 - val_loss: 0.0122 - val_acc: 0.9971\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0122 - acc: 0.9974 - val_loss: 0.0116 - val_acc: 0.9975\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0108 - acc: 0.9978 - val_loss: 0.0108 - val_acc: 0.9977\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0096 - acc: 0.9982 - val_loss: 0.0099 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0084 - acc: 0.9985 - val_loss: 0.0101 - val_acc: 0.9982\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0079 - acc: 0.9986 - val_loss: 0.0092 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0072 - acc: 0.9989 - val_loss: 0.0092 - val_acc: 0.9986\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0065 - acc: 0.9989 - val_loss: 0.0090 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0064 - acc: 0.9990 - val_loss: 0.0091 - val_acc: 0.9988\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0092 - val_acc: 0.9988\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 16us/step - loss: 0.1314 - acc: 0.9522 - val_loss: 0.0278 - val_acc: 0.9911\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0267 - acc: 0.9930 - val_loss: 0.0183 - val_acc: 0.9945\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0184 - acc: 0.9957 - val_loss: 0.0148 - val_acc: 0.9959\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0140 - acc: 0.9969 - val_loss: 0.0138 - val_acc: 0.9963\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0117 - acc: 0.9976 - val_loss: 0.0113 - val_acc: 0.9974\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0098 - acc: 0.9981 - val_loss: 0.0106 - val_acc: 0.9979\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0088 - acc: 0.9984 - val_loss: 0.0095 - val_acc: 0.9983\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0078 - acc: 0.9986 - val_loss: 0.0100 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0071 - acc: 0.9988 - val_loss: 0.0098 - val_acc: 0.9982\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 17us/step - loss: 0.1715 - acc: 0.9341 - val_loss: 0.0341 - val_acc: 0.9906\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0328 - acc: 0.9911 - val_loss: 0.0214 - val_acc: 0.9936\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0220 - acc: 0.9944 - val_loss: 0.0162 - val_acc: 0.9957\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0169 - acc: 0.9959 - val_loss: 0.0151 - val_acc: 0.9961\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0137 - acc: 0.9970 - val_loss: 0.0126 - val_acc: 0.9968\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0117 - acc: 0.9976 - val_loss: 0.0111 - val_acc: 0.9977\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0100 - acc: 0.9980 - val_loss: 0.0106 - val_acc: 0.9980\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0089 - acc: 0.9983 - val_loss: 0.0104 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0081 - acc: 0.9986 - val_loss: 0.0098 - val_acc: 0.9984\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0073 - acc: 0.9987 - val_loss: 0.0095 - val_acc: 0.9985\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0069 - acc: 0.9989 - val_loss: 0.0091 - val_acc: 0.9986\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0062 - acc: 0.9990 - val_loss: 0.0092 - val_acc: 0.9986\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0089 - val_acc: 0.9987\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0086 - val_acc: 0.9989\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9988\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9988\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 17us/step - loss: 0.1861 - acc: 0.9266 - val_loss: 0.0329 - val_acc: 0.9910\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0321 - acc: 0.9915 - val_loss: 0.0199 - val_acc: 0.9935\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0215 - acc: 0.9947 - val_loss: 0.0158 - val_acc: 0.9955\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0163 - acc: 0.9962 - val_loss: 0.0132 - val_acc: 0.9967\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0132 - acc: 0.9971 - val_loss: 0.0128 - val_acc: 0.9970\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0114 - acc: 0.9977 - val_loss: 0.0115 - val_acc: 0.9975\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0098 - acc: 0.9981 - val_loss: 0.0109 - val_acc: 0.9977\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0090 - acc: 0.9984 - val_loss: 0.0109 - val_acc: 0.9978\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0080 - acc: 0.9986 - val_loss: 0.0101 - val_acc: 0.9982\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0075 - acc: 0.9988 - val_loss: 0.0097 - val_acc: 0.9984\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0069 - acc: 0.9989 - val_loss: 0.0095 - val_acc: 0.9985\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0095 - val_acc: 0.9986\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0097 - val_acc: 0.9987\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0094 - val_acc: 0.9987\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0055 - acc: 0.9992 - val_loss: 0.0092 - val_acc: 0.9987\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0092 - val_acc: 0.9988\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0090 - val_acc: 0.9989\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Epoch 20/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0043 - acc: 0.9994 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.1261 - acc: 0.9542 - val_loss: 0.0265 - val_acc: 0.9921\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0270 - acc: 0.9929 - val_loss: 0.0188 - val_acc: 0.9946\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0179 - acc: 0.9957 - val_loss: 0.0140 - val_acc: 0.9965\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0138 - acc: 0.9970 - val_loss: 0.0126 - val_acc: 0.9971\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0121 - acc: 0.9976 - val_loss: 0.0116 - val_acc: 0.9975\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0101 - acc: 0.9980 - val_loss: 0.0104 - val_acc: 0.9979\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0090 - acc: 0.9983 - val_loss: 0.0098 - val_acc: 0.9983\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0079 - acc: 0.9986 - val_loss: 0.0094 - val_acc: 0.9986\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0074 - acc: 0.9988 - val_loss: 0.0095 - val_acc: 0.9986\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0066 - acc: 0.9989 - val_loss: 0.0091 - val_acc: 0.9987\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0092 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0057 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0090 - val_acc: 0.9989\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0052 - acc: 0.9992 - val_loss: 0.0090 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.1104 - acc: 0.9615 - val_loss: 0.0274 - val_acc: 0.9918\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0264 - acc: 0.9931 - val_loss: 0.0171 - val_acc: 0.9951\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0175 - acc: 0.9958 - val_loss: 0.0144 - val_acc: 0.9962\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0140 - acc: 0.9969 - val_loss: 0.0126 - val_acc: 0.9969\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0116 - acc: 0.9976 - val_loss: 0.0108 - val_acc: 0.9979\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0105 - acc: 0.9980 - val_loss: 0.0109 - val_acc: 0.9979\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0090 - acc: 0.9984 - val_loss: 0.0103 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.0098 - val_acc: 0.9984\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0073 - acc: 0.9988 - val_loss: 0.0093 - val_acc: 0.9987\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0067 - acc: 0.9989 - val_loss: 0.0093 - val_acc: 0.9987\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0062 - acc: 0.9990 - val_loss: 0.0092 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0092 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0055 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9988\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0090 - val_acc: 0.9989\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0092 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.1706 - acc: 0.9353 - val_loss: 0.0358 - val_acc: 0.9898\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0341 - acc: 0.9909 - val_loss: 0.0214 - val_acc: 0.9937\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0227 - acc: 0.9941 - val_loss: 0.0164 - val_acc: 0.9953\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0178 - acc: 0.9959 - val_loss: 0.0141 - val_acc: 0.9960\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0143 - acc: 0.9968 - val_loss: 0.0120 - val_acc: 0.9972\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0120 - acc: 0.9975 - val_loss: 0.0117 - val_acc: 0.9975\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0108 - acc: 0.9979 - val_loss: 0.0112 - val_acc: 0.9977\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0096 - acc: 0.9982 - val_loss: 0.0100 - val_acc: 0.9981\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0082 - acc: 0.9986 - val_loss: 0.0099 - val_acc: 0.9982\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0079 - acc: 0.9987 - val_loss: 0.0089 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0072 - acc: 0.9988 - val_loss: 0.0091 - val_acc: 0.9986\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0067 - acc: 0.9989 - val_loss: 0.0087 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0061 - acc: 0.9991 - val_loss: 0.0089 - val_acc: 0.9988\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0057 - acc: 0.9992 - val_loss: 0.0086 - val_acc: 0.9989\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9989\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.1269 - acc: 0.9567 - val_loss: 0.0287 - val_acc: 0.9915\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0285 - acc: 0.9923 - val_loss: 0.0185 - val_acc: 0.9946\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0191 - acc: 0.9953 - val_loss: 0.0161 - val_acc: 0.9957\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0151 - acc: 0.9966 - val_loss: 0.0128 - val_acc: 0.9969\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0125 - acc: 0.9974 - val_loss: 0.0122 - val_acc: 0.9970\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0104 - acc: 0.9980 - val_loss: 0.0108 - val_acc: 0.9976\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0093 - acc: 0.9984 - val_loss: 0.0096 - val_acc: 0.9980\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0081 - acc: 0.9986 - val_loss: 0.0094 - val_acc: 0.9984\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0071 - acc: 0.9988 - val_loss: 0.0088 - val_acc: 0.9986\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0065 - acc: 0.9989 - val_loss: 0.0086 - val_acc: 0.9987\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0086 - val_acc: 0.9988\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0056 - acc: 0.9992 - val_loss: 0.0086 - val_acc: 0.9989\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0084 - val_acc: 0.9990\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0048 - acc: 0.9993 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0083 - val_acc: 0.9991\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0042 - acc: 0.9995 - val_loss: 0.0082 - val_acc: 0.9991\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0040 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9991\n",
      "Epoch 20/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0037 - acc: 0.9995 - val_loss: 0.0085 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.1492 - acc: 0.9469 - val_loss: 0.0312 - val_acc: 0.9902\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0328 - acc: 0.9909 - val_loss: 0.0199 - val_acc: 0.9942\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0219 - acc: 0.9946 - val_loss: 0.0158 - val_acc: 0.9958\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0164 - acc: 0.9962 - val_loss: 0.0135 - val_acc: 0.9967\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0138 - acc: 0.9971 - val_loss: 0.0110 - val_acc: 0.9976\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0112 - acc: 0.9979 - val_loss: 0.0105 - val_acc: 0.9978\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0099 - acc: 0.9981 - val_loss: 0.0098 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0089 - acc: 0.9984 - val_loss: 0.0102 - val_acc: 0.9981\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0079 - acc: 0.9987 - val_loss: 0.0095 - val_acc: 0.9983\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0072 - acc: 0.9989 - val_loss: 0.0089 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0065 - acc: 0.9990 - val_loss: 0.0089 - val_acc: 0.9986\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0086 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0057 - acc: 0.9992 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9988\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.1492 - acc: 0.9525 - val_loss: 0.0315 - val_acc: 0.9902\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0293 - acc: 0.9918 - val_loss: 0.0189 - val_acc: 0.9948\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0192 - acc: 0.9952 - val_loss: 0.0156 - val_acc: 0.9957\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0146 - acc: 0.9969 - val_loss: 0.0129 - val_acc: 0.9968\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0123 - acc: 0.9975 - val_loss: 0.0117 - val_acc: 0.9972\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0103 - acc: 0.9981 - val_loss: 0.0103 - val_acc: 0.9979\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0090 - acc: 0.9983 - val_loss: 0.0099 - val_acc: 0.9983\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0082 - acc: 0.9986 - val_loss: 0.0096 - val_acc: 0.9984\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0073 - acc: 0.9988 - val_loss: 0.0093 - val_acc: 0.9986\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0066 - acc: 0.9990 - val_loss: 0.0086 - val_acc: 0.9988\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0085 - val_acc: 0.9989\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0053 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.1742 - acc: 0.9370 - val_loss: 0.0390 - val_acc: 0.9881\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0353 - acc: 0.9899 - val_loss: 0.0227 - val_acc: 0.9932\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0218 - acc: 0.9944 - val_loss: 0.0173 - val_acc: 0.9947\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0164 - acc: 0.9962 - val_loss: 0.0144 - val_acc: 0.9962\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0137 - acc: 0.9971 - val_loss: 0.0132 - val_acc: 0.9967\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0115 - acc: 0.9977 - val_loss: 0.0117 - val_acc: 0.9975\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0100 - acc: 0.9981 - val_loss: 0.0108 - val_acc: 0.9978\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0089 - acc: 0.9984 - val_loss: 0.0104 - val_acc: 0.9979\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0081 - acc: 0.9986 - val_loss: 0.0095 - val_acc: 0.9983\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0074 - acc: 0.9988 - val_loss: 0.0095 - val_acc: 0.9983\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0066 - acc: 0.9990 - val_loss: 0.0093 - val_acc: 0.9985\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0062 - acc: 0.9991 - val_loss: 0.0092 - val_acc: 0.9986\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0055 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0053 - acc: 0.9993 - val_loss: 0.0090 - val_acc: 0.9989\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0047 - acc: 0.9993 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0043 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.1382 - acc: 0.9562 - val_loss: 0.0263 - val_acc: 0.9924\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0269 - acc: 0.9928 - val_loss: 0.0167 - val_acc: 0.9953\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0176 - acc: 0.9959 - val_loss: 0.0145 - val_acc: 0.9960\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0138 - acc: 0.9971 - val_loss: 0.0117 - val_acc: 0.9972\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0114 - acc: 0.9978 - val_loss: 0.0110 - val_acc: 0.9975\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0094 - acc: 0.9983 - val_loss: 0.0103 - val_acc: 0.9979\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0085 - acc: 0.9985 - val_loss: 0.0094 - val_acc: 0.9983\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0076 - acc: 0.9988 - val_loss: 0.0098 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0069 - acc: 0.9989 - val_loss: 0.0090 - val_acc: 0.9986\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0064 - acc: 0.9990 - val_loss: 0.0087 - val_acc: 0.9987\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0086 - val_acc: 0.9988\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.2140 - acc: 0.9334 - val_loss: 0.0302 - val_acc: 0.9914\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0324 - acc: 0.9916 - val_loss: 0.0201 - val_acc: 0.9939\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0214 - acc: 0.9948 - val_loss: 0.0153 - val_acc: 0.9956\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0162 - acc: 0.9963 - val_loss: 0.0137 - val_acc: 0.9964\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0134 - acc: 0.9972 - val_loss: 0.0119 - val_acc: 0.9971\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0111 - acc: 0.9977 - val_loss: 0.0112 - val_acc: 0.9976\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0108 - val_acc: 0.9979\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0092 - acc: 0.9983 - val_loss: 0.0098 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0082 - acc: 0.9986 - val_loss: 0.0094 - val_acc: 0.9984\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0074 - acc: 0.9988 - val_loss: 0.0091 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0069 - acc: 0.9989 - val_loss: 0.0088 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0057 - acc: 0.9992 - val_loss: 0.0091 - val_acc: 0.9987\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.1647 - acc: 0.9375 - val_loss: 0.0317 - val_acc: 0.9905\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0316 - acc: 0.9914 - val_loss: 0.0204 - val_acc: 0.9943\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0209 - acc: 0.9948 - val_loss: 0.0157 - val_acc: 0.9957\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0160 - acc: 0.9964 - val_loss: 0.0139 - val_acc: 0.9966\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0130 - acc: 0.9972 - val_loss: 0.0115 - val_acc: 0.9973\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0111 - acc: 0.9978 - val_loss: 0.0116 - val_acc: 0.9975\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0097 - acc: 0.9982 - val_loss: 0.0101 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0086 - acc: 0.9985 - val_loss: 0.0099 - val_acc: 0.9983\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0078 - acc: 0.9988 - val_loss: 0.0092 - val_acc: 0.9985\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0070 - acc: 0.9989 - val_loss: 0.0096 - val_acc: 0.9985\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0067 - acc: 0.9990 - val_loss: 0.0089 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0061 - acc: 0.9991 - val_loss: 0.0091 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.1527 - acc: 0.9468 - val_loss: 0.0322 - val_acc: 0.9906\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0309 - acc: 0.9918 - val_loss: 0.0193 - val_acc: 0.9948\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0206 - acc: 0.9951 - val_loss: 0.0149 - val_acc: 0.9960\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0162 - acc: 0.9964 - val_loss: 0.0130 - val_acc: 0.9968\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0133 - acc: 0.9972 - val_loss: 0.0118 - val_acc: 0.9972\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0115 - acc: 0.9977 - val_loss: 0.0113 - val_acc: 0.9973\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0096 - acc: 0.9983 - val_loss: 0.0104 - val_acc: 0.9980\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0086 - acc: 0.9984 - val_loss: 0.0099 - val_acc: 0.9983\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0079 - acc: 0.9987 - val_loss: 0.0101 - val_acc: 0.9982\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0072 - acc: 0.9988 - val_loss: 0.0096 - val_acc: 0.9985\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0068 - acc: 0.9989 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0061 - acc: 0.9991 - val_loss: 0.0091 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0088 - val_acc: 0.9988\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0087 - val_acc: 0.9988\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0086 - val_acc: 0.9989\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0047 - acc: 0.9993 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0043 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 20/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0041 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9991\n",
      "Epoch 21/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0040 - acc: 0.9995 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 22/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0040 - acc: 0.9995 - val_loss: 0.0082 - val_acc: 0.9992\n",
      "Epoch 23/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0039 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9991\n",
      "Epoch 24/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0037 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.1365 - acc: 0.9479 - val_loss: 0.0302 - val_acc: 0.9906\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0291 - acc: 0.9923 - val_loss: 0.0181 - val_acc: 0.9947\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0190 - acc: 0.9952 - val_loss: 0.0148 - val_acc: 0.9961\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0148 - acc: 0.9967 - val_loss: 0.0126 - val_acc: 0.9969\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0120 - acc: 0.9974 - val_loss: 0.0112 - val_acc: 0.9976\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0105 - val_acc: 0.9979\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0090 - acc: 0.9983 - val_loss: 0.0101 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0085 - acc: 0.9985 - val_loss: 0.0099 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0098 - val_acc: 0.9983\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0070 - acc: 0.9988 - val_loss: 0.0090 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0066 - acc: 0.9989 - val_loss: 0.0092 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0060 - acc: 0.9990 - val_loss: 0.0092 - val_acc: 0.9987\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.1534 - acc: 0.9466 - val_loss: 0.0285 - val_acc: 0.9916\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0294 - acc: 0.9920 - val_loss: 0.0165 - val_acc: 0.9953\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0192 - acc: 0.9952 - val_loss: 0.0148 - val_acc: 0.9963\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0151 - acc: 0.9967 - val_loss: 0.0130 - val_acc: 0.9968\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0125 - acc: 0.9975 - val_loss: 0.0111 - val_acc: 0.9975\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0107 - acc: 0.9980 - val_loss: 0.0107 - val_acc: 0.9977\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0091 - acc: 0.9983 - val_loss: 0.0098 - val_acc: 0.9982\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0083 - acc: 0.9987 - val_loss: 0.0092 - val_acc: 0.9983\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0075 - acc: 0.9988 - val_loss: 0.0087 - val_acc: 0.9986\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0067 - acc: 0.9990 - val_loss: 0.0087 - val_acc: 0.9987\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0064 - acc: 0.9991 - val_loss: 0.0087 - val_acc: 0.9988\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0059 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9988\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.1850 - acc: 0.9371 - val_loss: 0.0355 - val_acc: 0.9891\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0364 - acc: 0.9898 - val_loss: 0.0205 - val_acc: 0.9941\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0244 - acc: 0.9935 - val_loss: 0.0170 - val_acc: 0.9953\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0186 - acc: 0.9954 - val_loss: 0.0146 - val_acc: 0.9962\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0154 - acc: 0.9964 - val_loss: 0.0124 - val_acc: 0.9969\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0128 - acc: 0.9972 - val_loss: 0.0124 - val_acc: 0.9970\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0111 - acc: 0.9977 - val_loss: 0.0109 - val_acc: 0.9975\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0100 - acc: 0.9981 - val_loss: 0.0104 - val_acc: 0.9980\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0090 - acc: 0.9984 - val_loss: 0.0102 - val_acc: 0.9981\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0079 - acc: 0.9987 - val_loss: 0.0098 - val_acc: 0.9984\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0073 - acc: 0.9988 - val_loss: 0.0095 - val_acc: 0.9985\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0064 - acc: 0.9990 - val_loss: 0.0094 - val_acc: 0.9986\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0061 - acc: 0.9991 - val_loss: 0.0092 - val_acc: 0.9987\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0089 - val_acc: 0.9988\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9988\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9988\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0084 - val_acc: 0.9990\n",
      "Epoch 20/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0041 - acc: 0.9995 - val_loss: 0.0084 - val_acc: 0.9990\n",
      "Epoch 21/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0041 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.1505 - acc: 0.9439 - val_loss: 0.0314 - val_acc: 0.9915\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0295 - acc: 0.9923 - val_loss: 0.0187 - val_acc: 0.9949\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0195 - acc: 0.9954 - val_loss: 0.0142 - val_acc: 0.9965\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0149 - acc: 0.9968 - val_loss: 0.0127 - val_acc: 0.9969\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0119 - acc: 0.9975 - val_loss: 0.0113 - val_acc: 0.9975\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0107 - acc: 0.9980 - val_loss: 0.0101 - val_acc: 0.9978\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0090 - acc: 0.9984 - val_loss: 0.0095 - val_acc: 0.9982\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0083 - acc: 0.9986 - val_loss: 0.0092 - val_acc: 0.9983\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0072 - acc: 0.9989 - val_loss: 0.0089 - val_acc: 0.9985\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0067 - acc: 0.9989 - val_loss: 0.0087 - val_acc: 0.9987\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0061 - acc: 0.9990 - val_loss: 0.0086 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0083 - val_acc: 0.9990\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0084 - val_acc: 0.9990\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0085 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.1263 - acc: 0.9525 - val_loss: 0.0288 - val_acc: 0.9911\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0287 - acc: 0.9924 - val_loss: 0.0181 - val_acc: 0.9943\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0191 - acc: 0.9955 - val_loss: 0.0144 - val_acc: 0.9960\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0150 - acc: 0.9967 - val_loss: 0.0118 - val_acc: 0.9970\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0122 - acc: 0.9974 - val_loss: 0.0115 - val_acc: 0.9972\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0101 - acc: 0.9980 - val_loss: 0.0111 - val_acc: 0.9977\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0088 - acc: 0.9984 - val_loss: 0.0101 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0080 - acc: 0.9986 - val_loss: 0.0099 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 5s 15us/step - loss: 0.0073 - acc: 0.9987 - val_loss: 0.0095 - val_acc: 0.9984\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0071 - acc: 0.9988 - val_loss: 0.0090 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0061 - acc: 0.9990 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0060 - acc: 0.9990 - val_loss: 0.0087 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0089 - val_acc: 0.9987\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 6s 16us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0091 - val_acc: 0.9987\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.1679 - acc: 0.9452 - val_loss: 0.0287 - val_acc: 0.9915\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0326 - acc: 0.9910 - val_loss: 0.0196 - val_acc: 0.9940\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0212 - acc: 0.9946 - val_loss: 0.0144 - val_acc: 0.9962\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0156 - acc: 0.9964 - val_loss: 0.0127 - val_acc: 0.9971\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0132 - acc: 0.9973 - val_loss: 0.0119 - val_acc: 0.9973\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0110 - acc: 0.9979 - val_loss: 0.0106 - val_acc: 0.9980\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0096 - acc: 0.9982 - val_loss: 0.0097 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0087 - acc: 0.9985 - val_loss: 0.0093 - val_acc: 0.9984\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0078 - acc: 0.9988 - val_loss: 0.0093 - val_acc: 0.9985\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0075 - acc: 0.9988 - val_loss: 0.0091 - val_acc: 0.9985\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0066 - acc: 0.9990 - val_loss: 0.0088 - val_acc: 0.9988\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.0088 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9988\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.1442 - acc: 0.9483 - val_loss: 0.0354 - val_acc: 0.9899\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0327 - acc: 0.9911 - val_loss: 0.0207 - val_acc: 0.9941\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0214 - acc: 0.9946 - val_loss: 0.0157 - val_acc: 0.9957\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0166 - acc: 0.9962 - val_loss: 0.0146 - val_acc: 0.9962\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0134 - acc: 0.9971 - val_loss: 0.0124 - val_acc: 0.9971\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0115 - acc: 0.9978 - val_loss: 0.0114 - val_acc: 0.9975\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0099 - acc: 0.9982 - val_loss: 0.0104 - val_acc: 0.9978\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0087 - acc: 0.9984 - val_loss: 0.0097 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0094 - val_acc: 0.9985\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0070 - acc: 0.9988 - val_loss: 0.0094 - val_acc: 0.9985\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0065 - acc: 0.9990 - val_loss: 0.0091 - val_acc: 0.9985\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0086 - val_acc: 0.9989\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0057 - acc: 0.9991 - val_loss: 0.0089 - val_acc: 0.9989\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0090 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.1611 - acc: 0.9477 - val_loss: 0.0294 - val_acc: 0.9920\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0322 - acc: 0.9916 - val_loss: 0.0199 - val_acc: 0.9941\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0214 - acc: 0.9948 - val_loss: 0.0156 - val_acc: 0.9956\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0165 - acc: 0.9965 - val_loss: 0.0135 - val_acc: 0.9967\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0136 - acc: 0.9973 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0117 - acc: 0.9978 - val_loss: 0.0106 - val_acc: 0.9980\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0103 - acc: 0.9981 - val_loss: 0.0106 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0089 - acc: 0.9986 - val_loss: 0.0098 - val_acc: 0.9984\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0079 - acc: 0.9987 - val_loss: 0.0094 - val_acc: 0.9986\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0073 - acc: 0.9989 - val_loss: 0.0093 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0066 - acc: 0.9990 - val_loss: 0.0093 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0089 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0055 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9989\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0052 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0086 - val_acc: 0.9989\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0048 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.1818 - acc: 0.9355 - val_loss: 0.0321 - val_acc: 0.9906\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0326 - acc: 0.9909 - val_loss: 0.0204 - val_acc: 0.9939\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0213 - acc: 0.9945 - val_loss: 0.0160 - val_acc: 0.9955\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0166 - acc: 0.9962 - val_loss: 0.0146 - val_acc: 0.9965\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0134 - acc: 0.9972 - val_loss: 0.0133 - val_acc: 0.9968\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0115 - acc: 0.9978 - val_loss: 0.0117 - val_acc: 0.9975\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0101 - acc: 0.9980 - val_loss: 0.0104 - val_acc: 0.9979\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0089 - acc: 0.9985 - val_loss: 0.0096 - val_acc: 0.9983\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0081 - acc: 0.9986 - val_loss: 0.0097 - val_acc: 0.9984\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0073 - acc: 0.9989 - val_loss: 0.0097 - val_acc: 0.9984\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.2043 - acc: 0.9307 - val_loss: 0.0308 - val_acc: 0.9907\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0340 - acc: 0.9903 - val_loss: 0.0198 - val_acc: 0.9942\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0224 - acc: 0.9943 - val_loss: 0.0164 - val_acc: 0.9956\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0168 - acc: 0.9962 - val_loss: 0.0152 - val_acc: 0.9963\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0137 - acc: 0.9971 - val_loss: 0.0137 - val_acc: 0.9968\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0119 - acc: 0.9976 - val_loss: 0.0123 - val_acc: 0.9973\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0105 - val_acc: 0.9979\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0091 - acc: 0.9984 - val_loss: 0.0104 - val_acc: 0.9981\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0080 - acc: 0.9986 - val_loss: 0.0100 - val_acc: 0.9982\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0074 - acc: 0.9988 - val_loss: 0.0093 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0068 - acc: 0.9990 - val_loss: 0.0093 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0061 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0089 - val_acc: 0.9988\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0053 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0048 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9989\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0043 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.1207 - acc: 0.9558 - val_loss: 0.0290 - val_acc: 0.9904\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0266 - acc: 0.9927 - val_loss: 0.0181 - val_acc: 0.9947\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0178 - acc: 0.9956 - val_loss: 0.0149 - val_acc: 0.9961\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0138 - acc: 0.9969 - val_loss: 0.0125 - val_acc: 0.9968\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0113 - acc: 0.9978 - val_loss: 0.0109 - val_acc: 0.9976\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0095 - acc: 0.9982 - val_loss: 0.0109 - val_acc: 0.9977\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0082 - acc: 0.9985 - val_loss: 0.0104 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 5s 15us/step - loss: 0.0074 - acc: 0.9988 - val_loss: 0.0093 - val_acc: 0.9985\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0070 - acc: 0.9989 - val_loss: 0.0093 - val_acc: 0.9985\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0060 - acc: 0.9990 - val_loss: 0.0092 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0091 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0056 - acc: 0.9992 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0091 - val_acc: 0.9987\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9989\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9989\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0042 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.1099 - acc: 0.9617 - val_loss: 0.0269 - val_acc: 0.9918\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0246 - acc: 0.9936 - val_loss: 0.0164 - val_acc: 0.9954\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0163 - acc: 0.9962 - val_loss: 0.0147 - val_acc: 0.9962\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0126 - acc: 0.9973 - val_loss: 0.0123 - val_acc: 0.9971\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0111 - val_acc: 0.9977\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0090 - acc: 0.9984 - val_loss: 0.0105 - val_acc: 0.9979\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0079 - acc: 0.9986 - val_loss: 0.0098 - val_acc: 0.9983\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0073 - acc: 0.9987 - val_loss: 0.0097 - val_acc: 0.9983\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0068 - acc: 0.9989 - val_loss: 0.0094 - val_acc: 0.9985\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0063 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9988\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0089 - val_acc: 0.9988\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0056 - acc: 0.9992 - val_loss: 0.0092 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0089 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.1770 - acc: 0.9363 - val_loss: 0.0333 - val_acc: 0.9908\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0341 - acc: 0.9905 - val_loss: 0.0230 - val_acc: 0.9929\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0228 - acc: 0.9939 - val_loss: 0.0173 - val_acc: 0.9950\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0179 - acc: 0.9956 - val_loss: 0.0143 - val_acc: 0.9962\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0141 - acc: 0.9968 - val_loss: 0.0138 - val_acc: 0.9966\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0122 - acc: 0.9975 - val_loss: 0.0119 - val_acc: 0.9972\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0107 - acc: 0.9979 - val_loss: 0.0108 - val_acc: 0.9978\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0092 - acc: 0.9983 - val_loss: 0.0105 - val_acc: 0.9980\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0081 - acc: 0.9986 - val_loss: 0.0098 - val_acc: 0.9983\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0071 - acc: 0.9988 - val_loss: 0.0091 - val_acc: 0.9985\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0065 - acc: 0.9989 - val_loss: 0.0097 - val_acc: 0.9985\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0062 - acc: 0.9990 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0056 - acc: 0.9992 - val_loss: 0.0095 - val_acc: 0.9987\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0052 - acc: 0.9993 - val_loss: 0.0089 - val_acc: 0.9988\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0090 - val_acc: 0.9988\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0090 - val_acc: 0.9989\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0043 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.1563 - acc: 0.9498 - val_loss: 0.0312 - val_acc: 0.9909\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0305 - acc: 0.9918 - val_loss: 0.0188 - val_acc: 0.9947\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0199 - acc: 0.9951 - val_loss: 0.0156 - val_acc: 0.9960\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0154 - acc: 0.9964 - val_loss: 0.0136 - val_acc: 0.9968\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0126 - acc: 0.9974 - val_loss: 0.0121 - val_acc: 0.9973\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0108 - acc: 0.9979 - val_loss: 0.0114 - val_acc: 0.9976\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0096 - acc: 0.9982 - val_loss: 0.0101 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0084 - acc: 0.9986 - val_loss: 0.0096 - val_acc: 0.9983\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0074 - acc: 0.9988 - val_loss: 0.0092 - val_acc: 0.9986\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0069 - acc: 0.9989 - val_loss: 0.0093 - val_acc: 0.9986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 15us/step - loss: 0.0065 - acc: 0.9990 - val_loss: 0.0090 - val_acc: 0.9988\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0055 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9989\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9989\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9990\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0041 - acc: 0.9994 - val_loss: 0.0084 - val_acc: 0.9990\n",
      "Epoch 20/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0037 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.1795 - acc: 0.9333 - val_loss: 0.0364 - val_acc: 0.9891\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0336 - acc: 0.9908 - val_loss: 0.0201 - val_acc: 0.9946\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0215 - acc: 0.9945 - val_loss: 0.0167 - val_acc: 0.9955\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0165 - acc: 0.9962 - val_loss: 0.0131 - val_acc: 0.9968\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0138 - acc: 0.9971 - val_loss: 0.0122 - val_acc: 0.9972\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0114 - acc: 0.9977 - val_loss: 0.0114 - val_acc: 0.9975\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0103 - acc: 0.9980 - val_loss: 0.0113 - val_acc: 0.9977\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0092 - acc: 0.9983 - val_loss: 0.0099 - val_acc: 0.9982\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0082 - acc: 0.9986 - val_loss: 0.0102 - val_acc: 0.9982\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0095 - val_acc: 0.9984\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0074 - acc: 0.9988 - val_loss: 0.0097 - val_acc: 0.9984\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0067 - acc: 0.9989 - val_loss: 0.0095 - val_acc: 0.9985\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0061 - acc: 0.9990 - val_loss: 0.0093 - val_acc: 0.9986\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0091 - val_acc: 0.9986\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0056 - acc: 0.9992 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0052 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9987\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0050 - acc: 0.9992 - val_loss: 0.0085 - val_acc: 0.9989\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0048 - acc: 0.9993 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0047 - acc: 0.9993 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.1642 - acc: 0.9369 - val_loss: 0.0299 - val_acc: 0.9915\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0313 - acc: 0.9917 - val_loss: 0.0189 - val_acc: 0.9944\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0207 - acc: 0.9948 - val_loss: 0.0156 - val_acc: 0.9958\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0160 - acc: 0.9963 - val_loss: 0.0132 - val_acc: 0.9968\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0132 - acc: 0.9972 - val_loss: 0.0115 - val_acc: 0.9973\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0111 - acc: 0.9978 - val_loss: 0.0109 - val_acc: 0.9977\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0100 - acc: 0.9981 - val_loss: 0.0104 - val_acc: 0.9979\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0088 - acc: 0.9984 - val_loss: 0.0100 - val_acc: 0.9981\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0082 - acc: 0.9986 - val_loss: 0.0090 - val_acc: 0.9984\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0073 - acc: 0.9988 - val_loss: 0.0095 - val_acc: 0.9984\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0066 - acc: 0.9990 - val_loss: 0.0091 - val_acc: 0.9986\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.1999 - acc: 0.9312 - val_loss: 0.0357 - val_acc: 0.9899\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0390 - acc: 0.9895 - val_loss: 0.0216 - val_acc: 0.9943\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0252 - acc: 0.9935 - val_loss: 0.0184 - val_acc: 0.9951\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0190 - acc: 0.9954 - val_loss: 0.0161 - val_acc: 0.9959\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 11us/step - loss: 0.0156 - acc: 0.9966 - val_loss: 0.0129 - val_acc: 0.9970\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0135 - acc: 0.9971 - val_loss: 0.0114 - val_acc: 0.9974\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0116 - acc: 0.9976 - val_loss: 0.0115 - val_acc: 0.9975\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0104 - acc: 0.9979 - val_loss: 0.0110 - val_acc: 0.9980\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0092 - acc: 0.9983 - val_loss: 0.0108 - val_acc: 0.9981\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0083 - acc: 0.9985 - val_loss: 0.0100 - val_acc: 0.9984\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0101 - val_acc: 0.9984\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0071 - acc: 0.9989 - val_loss: 0.0094 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0064 - acc: 0.9990 - val_loss: 0.0096 - val_acc: 0.9987\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0093 - val_acc: 0.9987\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0094 - val_acc: 0.9988\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0092 - val_acc: 0.9988\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0092 - val_acc: 0.9988\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0048 - acc: 0.9993 - val_loss: 0.0091 - val_acc: 0.9989\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0047 - acc: 0.9993 - val_loss: 0.0092 - val_acc: 0.9989\n",
      "Epoch 20/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0045 - acc: 0.9994 - val_loss: 0.0092 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.1985 - acc: 0.9279 - val_loss: 0.0361 - val_acc: 0.9898\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0349 - acc: 0.9909 - val_loss: 0.0212 - val_acc: 0.9937\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0228 - acc: 0.9945 - val_loss: 0.0158 - val_acc: 0.9954\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0175 - acc: 0.9961 - val_loss: 0.0141 - val_acc: 0.9964\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0137 - acc: 0.9971 - val_loss: 0.0122 - val_acc: 0.9972\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0118 - acc: 0.9976 - val_loss: 0.0116 - val_acc: 0.9975\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0106 - acc: 0.9980 - val_loss: 0.0106 - val_acc: 0.9979\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0094 - acc: 0.9983 - val_loss: 0.0105 - val_acc: 0.9980\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0086 - acc: 0.9985 - val_loss: 0.0098 - val_acc: 0.9983\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0077 - acc: 0.9988 - val_loss: 0.0093 - val_acc: 0.9986\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0069 - acc: 0.9989 - val_loss: 0.0089 - val_acc: 0.9987\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0068 - acc: 0.9990 - val_loss: 0.0092 - val_acc: 0.9987\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 0.0094 - val_acc: 0.9987\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.2056 - acc: 0.9277 - val_loss: 0.0350 - val_acc: 0.9903\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0369 - acc: 0.9902 - val_loss: 0.0215 - val_acc: 0.9943\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0241 - acc: 0.9939 - val_loss: 0.0168 - val_acc: 0.9954\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0180 - acc: 0.9959 - val_loss: 0.0135 - val_acc: 0.9967\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0146 - acc: 0.9970 - val_loss: 0.0121 - val_acc: 0.9971\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0122 - acc: 0.9975 - val_loss: 0.0113 - val_acc: 0.9974\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0107 - acc: 0.9980 - val_loss: 0.0101 - val_acc: 0.9981\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0094 - acc: 0.9983 - val_loss: 0.0103 - val_acc: 0.9981\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0084 - acc: 0.9986 - val_loss: 0.0095 - val_acc: 0.9983\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0078 - acc: 0.9987 - val_loss: 0.0097 - val_acc: 0.9983\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0068 - acc: 0.9989 - val_loss: 0.0094 - val_acc: 0.9986\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0065 - acc: 0.9990 - val_loss: 0.0090 - val_acc: 0.9986\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0061 - acc: 0.9991 - val_loss: 0.0089 - val_acc: 0.9987\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0086 - val_acc: 0.9989\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0090 - val_acc: 0.9988\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0047 - acc: 0.9993 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0049 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9991\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 5s 12us/step - loss: 0.0043 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9990\n",
      "Epoch 20/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0041 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.1476 - acc: 0.9431 - val_loss: 0.0323 - val_acc: 0.9902\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0295 - acc: 0.9922 - val_loss: 0.0190 - val_acc: 0.9944\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0194 - acc: 0.9951 - val_loss: 0.0166 - val_acc: 0.9953\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 4s 12us/step - loss: 0.0146 - acc: 0.9966 - val_loss: 0.0135 - val_acc: 0.9965\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 5s 13us/step - loss: 0.0123 - acc: 0.9974 - val_loss: 0.0117 - val_acc: 0.9973\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0102 - acc: 0.9979 - val_loss: 0.0115 - val_acc: 0.9976\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0088 - acc: 0.9983 - val_loss: 0.0099 - val_acc: 0.9982\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 5s 15us/step - loss: 0.0079 - acc: 0.9985 - val_loss: 0.0098 - val_acc: 0.9984\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0072 - acc: 0.9988 - val_loss: 0.0093 - val_acc: 0.9986\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 5s 15us/step - loss: 0.0068 - acc: 0.9989 - val_loss: 0.0095 - val_acc: 0.9985\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 5s 15us/step - loss: 0.0062 - acc: 0.9991 - val_loss: 0.0091 - val_acc: 0.9986\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0088 - val_acc: 0.9988\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 5s 15us/step - loss: 0.0055 - acc: 0.9992 - val_loss: 0.0091 - val_acc: 0.9988\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 5s 14us/step - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9988\n",
      "[0.7510917030567685, 0.748898678414097, 0.6991869918699187, 0.7522123893805309, 0.7456140350877193, 0.7813953488372092, 0.73109243697479, 0.748898678414097, 0.7456140350877193, 0.7577092511013216, 0.7078189300411522, 0.7727272727272727, 0.7400881057268723, 0.7924528301886793, 0.7264957264957265, 0.7850467289719627, 0.7887323943661971, 0.779342723004695, 0.748898678414097, 0.7131147540983606, 0.7555555555555555, 0.7522123893805309, 0.7049180327868853, 0.7264957264957265, 0.7924528301886793, 0.759825327510917, 0.6796875, 0.7443946188340808, 0.7942583732057418, 0.767123287671233, 0.7699115044247788, 0.783410138248848, 0.8058252427184466, 0.7699115044247788, 0.7304347826086957, 0.7798165137614678, 0.7341772151898734, 0.748898678414097, 0.7391304347826086, 0.7884615384615385, 0.7094017094017094, 0.736842105263158, 0.7777777777777777, 0.7747747747747746, 0.7555555555555555, 0.7555555555555555, 0.7678571428571428, 0.776255707762557, 0.6718749999999999, 0.7741935483870968, 0.7757009345794393, 0.743362831858407, 0.7813953488372092, 0.7904761904761906, 0.7962085308056872, 0.7073170731707316, 0.7813953488372092, 0.7327586206896551, 0.7924528301886793, 0.7522123893805309]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "callbacks = [EarlyStopping(monitor='val_loss',mode='min',patience=2, restore_best_weights = True)]\n",
    "results_control_accuracy = []\n",
    "for i in range(0,60):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=len(X.columns),kernel_initializer = 'he_normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(keras.optimizers.Adam(lr=0.001),'binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_resampled, Y_resampled, callbacks = callbacks,\n",
    "          epochs=30,validation_data = (X_test_test, Y_test_test),\n",
    "          batch_size=512)\n",
    "\n",
    "    y_test_pred= model.predict(X_test) > 0.5\n",
    "    \n",
    "    f1 = f1_score(Y_test, y_test_pred)\n",
    "    \n",
    "    results_control_accuracy.append(f1)\n",
    "    \n",
    "print(results_control_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_control_accuracy = pd.DataFrame(results_control_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Control Accuracy: 0    0.754945\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_control_accuracy = results_control_accuracy.mean()\n",
    "print(\"Mean Control Accuracy: {}\".format(mean_control_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Control Accuracy Results: 0    0.030112\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "std_control_accuracy = results_control_accuracy.std()\n",
    "print(\"Standard Deviation of Control Accuracy Results: {}\".format(std_control_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56821    43]\n",
      " [   13    85]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, y_test_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.66      0.87      0.75        98\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     56962\n",
      "   macro avg       0.83      0.93      0.88     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9992333690544885\n",
      "Test Accuracy:0.9988369286137506\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy: {}\\nTest Accuracy:{}'.format(history.history['acc'][-1], history.history['val_acc'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Roc curve generation\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, y_test_pred)\n",
    "plt.plot ([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label = 'Deep Learning')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Deep Learning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to determine learning rate \n",
    "# model = Sequential()\n",
    "# model.add(Dense(64, input_dim=len(X.columns), activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# from keras_lr_finder import LRFinder\n",
    "# lr_finder = LRFinder(model)\n",
    "# lr_finder.find(X_resampled, Y_resampled, .00001, 1, 512, 5)\n",
    "\n",
    "# lr_finder.plot_loss()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 11s 30us/step - loss: 0.1760 - acc: 0.9438 - val_loss: 0.0297 - val_acc: 0.9915\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0292 - acc: 0.9920 - val_loss: 0.0174 - val_acc: 0.9956\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0175 - acc: 0.9959 - val_loss: 0.0141 - val_acc: 0.9971\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0124 - acc: 0.9975 - val_loss: 0.0115 - val_acc: 0.9983\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0095 - acc: 0.9984 - val_loss: 0.0101 - val_acc: 0.9986\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0081 - acc: 0.9988 - val_loss: 0.0097 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0070 - acc: 0.9990 - val_loss: 0.0094 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0063 - acc: 0.9992 - val_loss: 0.0090 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0056 - acc: 0.9993 - val_loss: 0.0094 - val_acc: 0.9990\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0054 - acc: 0.9994 - val_loss: 0.0095 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 11s 31us/step - loss: 0.1168 - acc: 0.9585 - val_loss: 0.0194 - val_acc: 0.9942\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0240 - acc: 0.9934 - val_loss: 0.0152 - val_acc: 0.9964\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0148 - acc: 0.9967 - val_loss: 0.0125 - val_acc: 0.9976\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0108 - acc: 0.9980 - val_loss: 0.0102 - val_acc: 0.9987\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0083 - acc: 0.9987 - val_loss: 0.0096 - val_acc: 0.9989\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 6s 17us/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.0092 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0095 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0057 - acc: 0.9993 - val_loss: 0.0097 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 12s 32us/step - loss: 0.1207 - acc: 0.9589 - val_loss: 0.0217 - val_acc: 0.9940\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0223 - acc: 0.9944 - val_loss: 0.0140 - val_acc: 0.9971\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0137 - acc: 0.9972 - val_loss: 0.0109 - val_acc: 0.9982\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0102 - acc: 0.9982 - val_loss: 0.0100 - val_acc: 0.9986\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0081 - acc: 0.9987 - val_loss: 0.0100 - val_acc: 0.9989\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.0096 - val_acc: 0.9990\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0066 - acc: 0.9991 - val_loss: 0.0093 - val_acc: 0.9991\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0056 - acc: 0.9993 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0088 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9993\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0049 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9993\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0047 - acc: 0.9995 - val_loss: 0.0091 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 11s 30us/step - loss: 0.1329 - acc: 0.9539 - val_loss: 0.0194 - val_acc: 0.9943\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0225 - acc: 0.9942 - val_loss: 0.0131 - val_acc: 0.9971\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0138 - acc: 0.9971 - val_loss: 0.0108 - val_acc: 0.9984\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0100 - acc: 0.9983 - val_loss: 0.0108 - val_acc: 0.9986\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0081 - acc: 0.9988 - val_loss: 0.0100 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.0095 - val_acc: 0.9990\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0059 - acc: 0.9993 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0057 - acc: 0.9993 - val_loss: 0.0086 - val_acc: 0.9992\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 6s 17us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9993\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0047 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 12s 32us/step - loss: 0.1239 - acc: 0.9572 - val_loss: 0.0214 - val_acc: 0.9941\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0232 - acc: 0.9939 - val_loss: 0.0146 - val_acc: 0.9967\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0148 - acc: 0.9969 - val_loss: 0.0110 - val_acc: 0.9980\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0104 - acc: 0.9982 - val_loss: 0.0104 - val_acc: 0.9984\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 6s 17us/step - loss: 0.0088 - acc: 0.9987 - val_loss: 0.0097 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0073 - acc: 0.9989 - val_loss: 0.0096 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0063 - acc: 0.9991 - val_loss: 0.0095 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 6s 17us/step - loss: 0.0059 - acc: 0.9993 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0055 - acc: 0.9994 - val_loss: 0.0090 - val_acc: 0.9992\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0053 - acc: 0.9994 - val_loss: 0.0092 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0049 - acc: 0.9995 - val_loss: 0.0088 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.0088 - val_acc: 0.9993\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0088 - val_acc: 0.9993\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0045 - acc: 0.9996 - val_loss: 0.0087 - val_acc: 0.9993\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0093 - val_acc: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9993\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0043 - acc: 0.9995 - val_loss: 0.0088 - val_acc: 0.9993\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0089 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 11s 32us/step - loss: 0.1479 - acc: 0.9548 - val_loss: 0.0219 - val_acc: 0.9940\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0246 - acc: 0.9933 - val_loss: 0.0138 - val_acc: 0.9970\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0149 - acc: 0.9968 - val_loss: 0.0119 - val_acc: 0.9980\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0105 - acc: 0.9981 - val_loss: 0.0101 - val_acc: 0.9986\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 6s 17us/step - loss: 0.0084 - acc: 0.9986 - val_loss: 0.0098 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 6s 17us/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.0095 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0060 - acc: 0.9992 - val_loss: 0.0098 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0057 - acc: 0.9992 - val_loss: 0.0093 - val_acc: 0.9990\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 6s 17us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0092 - val_acc: 0.9990\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0047 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9992\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0089 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 11s 30us/step - loss: 0.1499 - acc: 0.9495 - val_loss: 0.0221 - val_acc: 0.9941\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0258 - acc: 0.9930 - val_loss: 0.0147 - val_acc: 0.9968\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0157 - acc: 0.9965 - val_loss: 0.0117 - val_acc: 0.9979\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0111 - acc: 0.9979 - val_loss: 0.0096 - val_acc: 0.9988\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0088 - acc: 0.9985 - val_loss: 0.0097 - val_acc: 0.9989\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0073 - acc: 0.9989 - val_loss: 0.0092 - val_acc: 0.9990\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0061 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0090 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0082 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0082 - val_acc: 0.9992\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9991\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0047 - acc: 0.9995 - val_loss: 0.0081 - val_acc: 0.9992\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0042 - acc: 0.9996 - val_loss: 0.0080 - val_acc: 0.9993\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9992\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0038 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 11s 30us/step - loss: 0.1554 - acc: 0.9460 - val_loss: 0.0275 - val_acc: 0.9913\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0284 - acc: 0.9919 - val_loss: 0.0168 - val_acc: 0.9960\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0173 - acc: 0.9960 - val_loss: 0.0123 - val_acc: 0.9976\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0124 - acc: 0.9974 - val_loss: 0.0111 - val_acc: 0.9983\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0099 - acc: 0.9984 - val_loss: 0.0097 - val_acc: 0.9986\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0078 - acc: 0.9988 - val_loss: 0.0094 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0070 - acc: 0.9990 - val_loss: 0.0091 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0061 - acc: 0.9991 - val_loss: 0.0093 - val_acc: 0.9990\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0053 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0084 - val_acc: 0.9991\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0085 - val_acc: 0.9991\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0041 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 11s 30us/step - loss: 0.1287 - acc: 0.9575 - val_loss: 0.0204 - val_acc: 0.9943\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0234 - acc: 0.9940 - val_loss: 0.0133 - val_acc: 0.9971\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0137 - acc: 0.9971 - val_loss: 0.0113 - val_acc: 0.9982\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0104 - acc: 0.9982 - val_loss: 0.0106 - val_acc: 0.9984\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0083 - acc: 0.9987 - val_loss: 0.0100 - val_acc: 0.9986\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0070 - acc: 0.9990 - val_loss: 0.0098 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0061 - acc: 0.9992 - val_loss: 0.0100 - val_acc: 0.9988\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0059 - acc: 0.9992 - val_loss: 0.0097 - val_acc: 0.9989\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0093 - val_acc: 0.9989\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0049 - acc: 0.9995 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0088 - val_acc: 0.9992\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0047 - acc: 0.9995 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0045 - acc: 0.9996 - val_loss: 0.0090 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 11s 30us/step - loss: 0.1536 - acc: 0.9493 - val_loss: 0.0291 - val_acc: 0.9917\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0259 - acc: 0.9932 - val_loss: 0.0155 - val_acc: 0.9965\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0159 - acc: 0.9964 - val_loss: 0.0127 - val_acc: 0.9978\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0111 - acc: 0.9979 - val_loss: 0.0115 - val_acc: 0.9983\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0090 - acc: 0.9985 - val_loss: 0.0105 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0075 - acc: 0.9989 - val_loss: 0.0096 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0064 - acc: 0.9991 - val_loss: 0.0094 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0060 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0088 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0084 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0092 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 11s 30us/step - loss: 0.1531 - acc: 0.9481 - val_loss: 0.0224 - val_acc: 0.9933\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0255 - acc: 0.9931 - val_loss: 0.0155 - val_acc: 0.9966\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0156 - acc: 0.9965 - val_loss: 0.0131 - val_acc: 0.9977\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0112 - acc: 0.9979 - val_loss: 0.0115 - val_acc: 0.9983\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0089 - acc: 0.9986 - val_loss: 0.0108 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0080 - acc: 0.9988 - val_loss: 0.0109 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.0104 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0093 - val_acc: 0.9990\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0055 - acc: 0.9993 - val_loss: 0.0095 - val_acc: 0.9990\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0055 - acc: 0.9994 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0053 - acc: 0.9994 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0049 - acc: 0.9995 - val_loss: 0.0088 - val_acc: 0.9992\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0049 - acc: 0.9995 - val_loss: 0.0090 - val_acc: 0.9992\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0045 - acc: 0.9996 - val_loss: 0.0089 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 11s 31us/step - loss: 0.1455 - acc: 0.9490 - val_loss: 0.0245 - val_acc: 0.9920\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0272 - acc: 0.9923 - val_loss: 0.0154 - val_acc: 0.9962\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0162 - acc: 0.9963 - val_loss: 0.0139 - val_acc: 0.9971\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0116 - acc: 0.9977 - val_loss: 0.0110 - val_acc: 0.9982\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0093 - acc: 0.9985 - val_loss: 0.0093 - val_acc: 0.9989\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0077 - acc: 0.9989 - val_loss: 0.0091 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0067 - acc: 0.9991 - val_loss: 0.0086 - val_acc: 0.9991\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0059 - acc: 0.9992 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0053 - acc: 0.9993 - val_loss: 0.0084 - val_acc: 0.9992\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0084 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.0085 - val_acc: 0.9991\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0049 - acc: 0.9995 - val_loss: 0.0080 - val_acc: 0.9993\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0084 - val_acc: 0.9993\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0084 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 12s 32us/step - loss: 0.1451 - acc: 0.9509 - val_loss: 0.0231 - val_acc: 0.9934\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0257 - acc: 0.9930 - val_loss: 0.0153 - val_acc: 0.9965\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0148 - acc: 0.9967 - val_loss: 0.0122 - val_acc: 0.9978\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0110 - acc: 0.9981 - val_loss: 0.0102 - val_acc: 0.9985\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0089 - acc: 0.9986 - val_loss: 0.0097 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0076 - acc: 0.9990 - val_loss: 0.0095 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0061 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0058 - acc: 0.9993 - val_loss: 0.0086 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0056 - acc: 0.9994 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 11s 32us/step - loss: 0.1422 - acc: 0.9531 - val_loss: 0.0208 - val_acc: 0.9944\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0240 - acc: 0.9939 - val_loss: 0.0135 - val_acc: 0.9974\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0145 - acc: 0.9969 - val_loss: 0.0111 - val_acc: 0.9983\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0108 - acc: 0.9980 - val_loss: 0.0096 - val_acc: 0.9987\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0085 - acc: 0.9986 - val_loss: 0.0092 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0076 - acc: 0.9989 - val_loss: 0.0086 - val_acc: 0.9991\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 6s 18us/step - loss: 0.0064 - acc: 0.9991 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0087 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 11s 31us/step - loss: 0.1195 - acc: 0.9574 - val_loss: 0.0200 - val_acc: 0.9943\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0215 - acc: 0.9946 - val_loss: 0.0121 - val_acc: 0.9976\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0131 - acc: 0.9974 - val_loss: 0.0107 - val_acc: 0.9984\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0095 - acc: 0.9984 - val_loss: 0.0094 - val_acc: 0.9989\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0072 - acc: 0.9989 - val_loss: 0.0091 - val_acc: 0.9990\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0066 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0086 - val_acc: 0.9991\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0049 - acc: 0.9994 - val_loss: 0.0083 - val_acc: 0.9992\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9993\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0041 - acc: 0.9996 - val_loss: 0.0082 - val_acc: 0.9993\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0086 - val_acc: 0.9992\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0038 - acc: 0.9996 - val_loss: 0.0081 - val_acc: 0.9993\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0038 - acc: 0.9996 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0086 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 12s 34us/step - loss: 0.1587 - acc: 0.9495 - val_loss: 0.0243 - val_acc: 0.9927\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0266 - acc: 0.9926 - val_loss: 0.0163 - val_acc: 0.9963\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0171 - acc: 0.9962 - val_loss: 0.0138 - val_acc: 0.9974\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0118 - acc: 0.9978 - val_loss: 0.0106 - val_acc: 0.9984\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0097 - acc: 0.9984 - val_loss: 0.0098 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0080 - acc: 0.9988 - val_loss: 0.0095 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0066 - acc: 0.9991 - val_loss: 0.0096 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0061 - acc: 0.9992 - val_loss: 0.0096 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 12s 33us/step - loss: 0.1287 - acc: 0.9561 - val_loss: 0.0256 - val_acc: 0.9917\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0264 - acc: 0.9931 - val_loss: 0.0157 - val_acc: 0.9964\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0153 - acc: 0.9967 - val_loss: 0.0125 - val_acc: 0.9979\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0111 - acc: 0.9980 - val_loss: 0.0117 - val_acc: 0.9981\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0084 - acc: 0.9987 - val_loss: 0.0099 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0071 - acc: 0.9990 - val_loss: 0.0097 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0063 - acc: 0.9992 - val_loss: 0.0093 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0056 - acc: 0.9993 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9993\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0047 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9993\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0044 - acc: 0.9996 - val_loss: 0.0090 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 12s 32us/step - loss: 0.1425 - acc: 0.9519 - val_loss: 0.0202 - val_acc: 0.9943\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0237 - acc: 0.9938 - val_loss: 0.0136 - val_acc: 0.9969\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0136 - acc: 0.9972 - val_loss: 0.0115 - val_acc: 0.9980\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0098 - acc: 0.9982 - val_loss: 0.0102 - val_acc: 0.9984\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0076 - acc: 0.9989 - val_loss: 0.0090 - val_acc: 0.9989\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0069 - acc: 0.9991 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0060 - acc: 0.9992 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0083 - val_acc: 0.9992\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0080 - val_acc: 0.9992\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0084 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0078 - val_acc: 0.9994\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0040 - acc: 0.9995 - val_loss: 0.0080 - val_acc: 0.9993\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0044 - acc: 0.9996 - val_loss: 0.0079 - val_acc: 0.9994\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 13s 35us/step - loss: 0.1648 - acc: 0.9459 - val_loss: 0.0257 - val_acc: 0.9923\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0271 - acc: 0.9924 - val_loss: 0.0148 - val_acc: 0.9963\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0166 - acc: 0.9962 - val_loss: 0.0116 - val_acc: 0.9980\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0118 - acc: 0.9978 - val_loss: 0.0119 - val_acc: 0.9983\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0092 - acc: 0.9984 - val_loss: 0.0102 - val_acc: 0.9986\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0080 - acc: 0.9988 - val_loss: 0.0098 - val_acc: 0.9986\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0068 - acc: 0.9990 - val_loss: 0.0091 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0063 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0056 - acc: 0.9993 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0053 - acc: 0.9994 - val_loss: 0.0084 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0084 - val_acc: 0.9992\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9993\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0042 - acc: 0.9995 - val_loss: 0.0078 - val_acc: 0.9993\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0042 - acc: 0.9996 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0040 - acc: 0.9996 - val_loss: 0.0086 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 12s 33us/step - loss: 0.1196 - acc: 0.9588 - val_loss: 0.0196 - val_acc: 0.9946\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0235 - acc: 0.9936 - val_loss: 0.0142 - val_acc: 0.9968\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0146 - acc: 0.9968 - val_loss: 0.0115 - val_acc: 0.9980\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0105 - acc: 0.9981 - val_loss: 0.0107 - val_acc: 0.9985\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0084 - acc: 0.9987 - val_loss: 0.0103 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.0095 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0060 - acc: 0.9992 - val_loss: 0.0094 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0056 - acc: 0.9993 - val_loss: 0.0094 - val_acc: 0.9990\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0055 - acc: 0.9993 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0084 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 12s 33us/step - loss: 0.1650 - acc: 0.9471 - val_loss: 0.0295 - val_acc: 0.9909\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0272 - acc: 0.9927 - val_loss: 0.0148 - val_acc: 0.9966\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0164 - acc: 0.9964 - val_loss: 0.0132 - val_acc: 0.9974\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.0110 - val_acc: 0.9983\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0093 - acc: 0.9984 - val_loss: 0.0100 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0078 - acc: 0.9988 - val_loss: 0.0098 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0070 - acc: 0.9990 - val_loss: 0.0092 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0057 - acc: 0.9993 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0053 - acc: 0.9994 - val_loss: 0.0088 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9992\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0085 - val_acc: 0.9993\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0085 - val_acc: 0.9993\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0042 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9993\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0040 - acc: 0.9996 - val_loss: 0.0084 - val_acc: 0.9993\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0040 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9993\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0087 - val_acc: 0.9993\n",
      "Epoch 20/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0085 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 13s 35us/step - loss: 0.1361 - acc: 0.9547 - val_loss: 0.0239 - val_acc: 0.9926\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0249 - acc: 0.9934 - val_loss: 0.0156 - val_acc: 0.9964\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0152 - acc: 0.9967 - val_loss: 0.0115 - val_acc: 0.9978\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0107 - acc: 0.9981 - val_loss: 0.0108 - val_acc: 0.9983\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0083 - acc: 0.9987 - val_loss: 0.0096 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0070 - acc: 0.9990 - val_loss: 0.0091 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0064 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0055 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0050 - acc: 0.9995 - val_loss: 0.0082 - val_acc: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0084 - val_acc: 0.9994\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 12s 33us/step - loss: 0.1316 - acc: 0.9540 - val_loss: 0.0238 - val_acc: 0.9925\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0244 - acc: 0.9935 - val_loss: 0.0134 - val_acc: 0.9970\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0149 - acc: 0.9968 - val_loss: 0.0115 - val_acc: 0.9979\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0110 - acc: 0.9980 - val_loss: 0.0102 - val_acc: 0.9985\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0084 - acc: 0.9987 - val_loss: 0.0100 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0073 - acc: 0.9989 - val_loss: 0.0095 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0063 - acc: 0.9991 - val_loss: 0.0089 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0057 - acc: 0.9992 - val_loss: 0.0092 - val_acc: 0.9989\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0053 - acc: 0.9993 - val_loss: 0.0091 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 12s 34us/step - loss: 0.1702 - acc: 0.9425 - val_loss: 0.0258 - val_acc: 0.9917\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0276 - acc: 0.9923 - val_loss: 0.0161 - val_acc: 0.9959\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0171 - acc: 0.9962 - val_loss: 0.0126 - val_acc: 0.9975\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0116 - acc: 0.9978 - val_loss: 0.0114 - val_acc: 0.9981\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0092 - acc: 0.9985 - val_loss: 0.0098 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0072 - acc: 0.9989 - val_loss: 0.0094 - val_acc: 0.9990\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0067 - acc: 0.9991 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0060 - acc: 0.9992 - val_loss: 0.0090 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0056 - acc: 0.9993 - val_loss: 0.0084 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0049 - acc: 0.9994 - val_loss: 0.0081 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0082 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0081 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 13s 36us/step - loss: 0.1669 - acc: 0.9462 - val_loss: 0.0295 - val_acc: 0.9915\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0278 - acc: 0.9925 - val_loss: 0.0190 - val_acc: 0.9953\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0173 - acc: 0.9961 - val_loss: 0.0135 - val_acc: 0.9976\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0124 - acc: 0.9976 - val_loss: 0.0118 - val_acc: 0.9980\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0099 - acc: 0.9983 - val_loss: 0.0108 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0081 - acc: 0.9988 - val_loss: 0.0106 - val_acc: 0.9987\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0071 - acc: 0.9989 - val_loss: 0.0098 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0065 - acc: 0.9991 - val_loss: 0.0097 - val_acc: 0.9990\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0061 - acc: 0.9992 - val_loss: 0.0092 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0059 - acc: 0.9992 - val_loss: 0.0094 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0053 - acc: 0.9994 - val_loss: 0.0094 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 13s 37us/step - loss: 0.1530 - acc: 0.9470 - val_loss: 0.0213 - val_acc: 0.9938\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0260 - acc: 0.9929 - val_loss: 0.0144 - val_acc: 0.9968\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0161 - acc: 0.9964 - val_loss: 0.0123 - val_acc: 0.9978\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0116 - acc: 0.9979 - val_loss: 0.0108 - val_acc: 0.9984\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0095 - acc: 0.9984 - val_loss: 0.0098 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0082 - acc: 0.9989 - val_loss: 0.0096 - val_acc: 0.9987\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0069 - acc: 0.9991 - val_loss: 0.0092 - val_acc: 0.9988\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9990\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0056 - acc: 0.9993 - val_loss: 0.0090 - val_acc: 0.9990\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0092 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 13s 35us/step - loss: 0.1155 - acc: 0.9593 - val_loss: 0.0180 - val_acc: 0.9952\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0213 - acc: 0.9947 - val_loss: 0.0135 - val_acc: 0.9971\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0135 - acc: 0.9972 - val_loss: 0.0111 - val_acc: 0.9981\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0096 - acc: 0.9983 - val_loss: 0.0103 - val_acc: 0.9985\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0079 - acc: 0.9988 - val_loss: 0.0102 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0065 - acc: 0.9991 - val_loss: 0.0093 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0060 - acc: 0.9992 - val_loss: 0.0093 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0047 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0085 - val_acc: 0.9991\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9992\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0040 - acc: 0.9996 - val_loss: 0.0080 - val_acc: 0.9993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0038 - acc: 0.9996 - val_loss: 0.0081 - val_acc: 0.9993\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0081 - val_acc: 0.9994\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 12s 34us/step - loss: 0.1806 - acc: 0.9436 - val_loss: 0.0268 - val_acc: 0.9916\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0304 - acc: 0.9914 - val_loss: 0.0169 - val_acc: 0.9959\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0173 - acc: 0.9960 - val_loss: 0.0125 - val_acc: 0.9977\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0126 - acc: 0.9975 - val_loss: 0.0113 - val_acc: 0.9983\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0100 - acc: 0.9983 - val_loss: 0.0099 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0080 - acc: 0.9987 - val_loss: 0.0097 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0072 - acc: 0.9990 - val_loss: 0.0091 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0057 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0088 - val_acc: 0.9991\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 13s 36us/step - loss: 0.1283 - acc: 0.9538 - val_loss: 0.0225 - val_acc: 0.9934\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0225 - acc: 0.9942 - val_loss: 0.0142 - val_acc: 0.9968\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0140 - acc: 0.9971 - val_loss: 0.0122 - val_acc: 0.9978\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0103 - acc: 0.9982 - val_loss: 0.0108 - val_acc: 0.9983\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0084 - acc: 0.9987 - val_loss: 0.0094 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.0093 - val_acc: 0.9990\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0061 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9991\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0057 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0084 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0084 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9992\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0041 - acc: 0.9996 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0040 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9993\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0040 - acc: 0.9996 - val_loss: 0.0086 - val_acc: 0.9993\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0081 - val_acc: 0.9993\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9993\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0036 - acc: 0.9996 - val_loss: 0.0084 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 14s 38us/step - loss: 0.1002 - acc: 0.9652 - val_loss: 0.0176 - val_acc: 0.9955\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0208 - acc: 0.9947 - val_loss: 0.0129 - val_acc: 0.9971\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0134 - acc: 0.9973 - val_loss: 0.0112 - val_acc: 0.9982\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0091 - acc: 0.9984 - val_loss: 0.0106 - val_acc: 0.9986\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0078 - acc: 0.9988 - val_loss: 0.0092 - val_acc: 0.9989\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0068 - acc: 0.9991 - val_loss: 0.0095 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0059 - acc: 0.9992 - val_loss: 0.0092 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0055 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0049 - acc: 0.9994 - val_loss: 0.0090 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.0090 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 13s 36us/step - loss: 0.1181 - acc: 0.9564 - val_loss: 0.0226 - val_acc: 0.9933\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0222 - acc: 0.9943 - val_loss: 0.0143 - val_acc: 0.9967\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0143 - acc: 0.9970 - val_loss: 0.0112 - val_acc: 0.9980\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0101 - acc: 0.9982 - val_loss: 0.0104 - val_acc: 0.9985\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0083 - acc: 0.9987 - val_loss: 0.0094 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0070 - acc: 0.9990 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0065 - acc: 0.9991 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0053 - acc: 0.9993 - val_loss: 0.0086 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 13s 36us/step - loss: 0.1462 - acc: 0.9511 - val_loss: 0.0241 - val_acc: 0.9929\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0243 - acc: 0.9936 - val_loss: 0.0143 - val_acc: 0.9968\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0140 - acc: 0.9969 - val_loss: 0.0107 - val_acc: 0.9984\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0100 - acc: 0.9981 - val_loss: 0.0102 - val_acc: 0.9986\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0078 - acc: 0.9988 - val_loss: 0.0098 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0069 - acc: 0.9991 - val_loss: 0.0093 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0059 - acc: 0.9993 - val_loss: 0.0089 - val_acc: 0.9991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0048 - acc: 0.9994 - val_loss: 0.0089 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9993\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0043 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9992\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0043 - acc: 0.9996 - val_loss: 0.0086 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 13s 36us/step - loss: 0.1342 - acc: 0.9548 - val_loss: 0.0249 - val_acc: 0.9934\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0241 - acc: 0.9938 - val_loss: 0.0158 - val_acc: 0.9966\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0145 - acc: 0.9969 - val_loss: 0.0111 - val_acc: 0.9980\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0099 - acc: 0.9983 - val_loss: 0.0105 - val_acc: 0.9984\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0080 - acc: 0.9987 - val_loss: 0.0099 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0065 - acc: 0.9990 - val_loss: 0.0093 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0061 - acc: 0.9992 - val_loss: 0.0095 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0095 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 16s 43us/step - loss: 0.1377 - acc: 0.9527 - val_loss: 0.0226 - val_acc: 0.9932\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0267 - acc: 0.9926 - val_loss: 0.0153 - val_acc: 0.9963\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0161 - acc: 0.9964 - val_loss: 0.0128 - val_acc: 0.9979\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0120 - acc: 0.9977 - val_loss: 0.0112 - val_acc: 0.9985\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0094 - acc: 0.9984 - val_loss: 0.0110 - val_acc: 0.9986\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0076 - acc: 0.9989 - val_loss: 0.0106 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0070 - acc: 0.9990 - val_loss: 0.0096 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0093 - val_acc: 0.9990\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0057 - acc: 0.9993 - val_loss: 0.0093 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0054 - acc: 0.9994 - val_loss: 0.0094 - val_acc: 0.9990\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.0091 - val_acc: 0.9992\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0047 - acc: 0.9995 - val_loss: 0.0088 - val_acc: 0.9993\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0092 - val_acc: 0.9992\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.0085 - val_acc: 0.9993\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0088 - val_acc: 0.9993\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0043 - acc: 0.9996 - val_loss: 0.0090 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 13s 36us/step - loss: 0.1385 - acc: 0.9522 - val_loss: 0.0234 - val_acc: 0.9933\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0253 - acc: 0.9931 - val_loss: 0.0160 - val_acc: 0.9967\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0149 - acc: 0.9967 - val_loss: 0.0126 - val_acc: 0.9978\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0111 - acc: 0.9980 - val_loss: 0.0103 - val_acc: 0.9986\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0083 - acc: 0.9986 - val_loss: 0.0099 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0069 - acc: 0.9989 - val_loss: 0.0095 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0062 - acc: 0.9991 - val_loss: 0.0093 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0090 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0090 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0048 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0084 - val_acc: 0.9993\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0042 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9992\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0042 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9993\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9993\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0036 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9993\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0038 - acc: 0.9996 - val_loss: 0.0081 - val_acc: 0.9993\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0036 - acc: 0.9996 - val_loss: 0.0076 - val_acc: 0.9994\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0078 - val_acc: 0.9993\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0034 - acc: 0.9996 - val_loss: 0.0073 - val_acc: 0.9993\n",
      "Epoch 20/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0032 - acc: 0.9996 - val_loss: 0.0075 - val_acc: 0.9994\n",
      "Epoch 21/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0073 - val_acc: 0.9994\n",
      "Epoch 22/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0032 - acc: 0.9996 - val_loss: 0.0073 - val_acc: 0.9994\n",
      "Epoch 23/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0028 - acc: 0.9997 - val_loss: 0.0076 - val_acc: 0.9994\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 13s 37us/step - loss: 0.1292 - acc: 0.9559 - val_loss: 0.0211 - val_acc: 0.9940\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0248 - acc: 0.9934 - val_loss: 0.0147 - val_acc: 0.9966\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0149 - acc: 0.9967 - val_loss: 0.0122 - val_acc: 0.9976\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0110 - acc: 0.9980 - val_loss: 0.0106 - val_acc: 0.9984\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0089 - acc: 0.9986 - val_loss: 0.0099 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0073 - acc: 0.9990 - val_loss: 0.0093 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0093 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0055 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0049 - acc: 0.9995 - val_loss: 0.0088 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9993\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0045 - acc: 0.9996 - val_loss: 0.0086 - val_acc: 0.9993\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0046 - acc: 0.9996 - val_loss: 0.0085 - val_acc: 0.9993\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0044 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9993\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0043 - acc: 0.9995 - val_loss: 0.0083 - val_acc: 0.9994\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0040 - acc: 0.9996 - val_loss: 0.0084 - val_acc: 0.9993\n",
      "Epoch 17/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0040 - acc: 0.9996 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 18/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0082 - val_acc: 0.9994\n",
      "Epoch 19/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0038 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9995\n",
      "Epoch 20/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0037 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9995\n",
      "Epoch 21/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0084 - val_acc: 0.9994\n",
      "Epoch 22/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0040 - acc: 0.9996 - val_loss: 0.0081 - val_acc: 0.9994\n",
      "Epoch 23/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0038 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9995\n",
      "Epoch 24/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0035 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9995\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 14s 37us/step - loss: 0.1396 - acc: 0.9519 - val_loss: 0.0210 - val_acc: 0.9937\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0265 - acc: 0.9930 - val_loss: 0.0137 - val_acc: 0.9971\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0163 - acc: 0.9964 - val_loss: 0.0116 - val_acc: 0.9979\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0115 - acc: 0.9979 - val_loss: 0.0105 - val_acc: 0.9985\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0091 - acc: 0.9985 - val_loss: 0.0099 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0073 - acc: 0.9989 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0063 - acc: 0.9991 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0058 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0053 - acc: 0.9994 - val_loss: 0.0084 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0048 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0083 - val_acc: 0.9991\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0082 - val_acc: 0.9993\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0041 - acc: 0.9995 - val_loss: 0.0081 - val_acc: 0.9993\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0041 - acc: 0.9995 - val_loss: 0.0081 - val_acc: 0.9993\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0037 - acc: 0.9996 - val_loss: 0.0084 - val_acc: 0.9993\n",
      "Epoch 16/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0082 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 14s 37us/step - loss: 0.1242 - acc: 0.9566 - val_loss: 0.0208 - val_acc: 0.9940\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0224 - acc: 0.9943 - val_loss: 0.0126 - val_acc: 0.9974\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0137 - acc: 0.9971 - val_loss: 0.0104 - val_acc: 0.9982\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0100 - acc: 0.9982 - val_loss: 0.0096 - val_acc: 0.9987\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0077 - acc: 0.9988 - val_loss: 0.0094 - val_acc: 0.9989\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0065 - acc: 0.9991 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0061 - acc: 0.9992 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0090 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 13s 37us/step - loss: 0.1678 - acc: 0.9448 - val_loss: 0.0232 - val_acc: 0.9939\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0271 - acc: 0.9927 - val_loss: 0.0130 - val_acc: 0.9973\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0166 - acc: 0.9960 - val_loss: 0.0112 - val_acc: 0.9980\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0116 - acc: 0.9977 - val_loss: 0.0104 - val_acc: 0.9985\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0091 - acc: 0.9985 - val_loss: 0.0101 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0075 - acc: 0.9989 - val_loss: 0.0095 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0065 - acc: 0.9991 - val_loss: 0.0097 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0056 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0052 - acc: 0.9993 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0047 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 18us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0085 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363930/363930 [==============================] - 14s 39us/step - loss: 0.1429 - acc: 0.9500 - val_loss: 0.0280 - val_acc: 0.9908\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0273 - acc: 0.9924 - val_loss: 0.0154 - val_acc: 0.9965\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0163 - acc: 0.9962 - val_loss: 0.0118 - val_acc: 0.9980\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0108 - acc: 0.9979 - val_loss: 0.0104 - val_acc: 0.9986\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0088 - acc: 0.9986 - val_loss: 0.0099 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0068 - acc: 0.9990 - val_loss: 0.0096 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0061 - acc: 0.9992 - val_loss: 0.0094 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0055 - acc: 0.9993 - val_loss: 0.0094 - val_acc: 0.9989\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0092 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0089 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 14s 38us/step - loss: 0.1568 - acc: 0.9473 - val_loss: 0.0277 - val_acc: 0.9916\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0288 - acc: 0.9920 - val_loss: 0.0167 - val_acc: 0.9960\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0172 - acc: 0.9961 - val_loss: 0.0125 - val_acc: 0.9976\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0115 - acc: 0.9978 - val_loss: 0.0112 - val_acc: 0.9982\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0095 - acc: 0.9984 - val_loss: 0.0099 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0077 - acc: 0.9988 - val_loss: 0.0099 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0072 - acc: 0.9990 - val_loss: 0.0095 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0060 - acc: 0.9992 - val_loss: 0.0093 - val_acc: 0.9990\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0057 - acc: 0.9993 - val_loss: 0.0095 - val_acc: 0.9990\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0084 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9992\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 14s 38us/step - loss: 0.1711 - acc: 0.9418 - val_loss: 0.0277 - val_acc: 0.9911\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0277 - acc: 0.9926 - val_loss: 0.0169 - val_acc: 0.9959\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0169 - acc: 0.9962 - val_loss: 0.0131 - val_acc: 0.9975\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0120 - acc: 0.9975 - val_loss: 0.0116 - val_acc: 0.9982\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0093 - acc: 0.9984 - val_loss: 0.0109 - val_acc: 0.9985\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0080 - acc: 0.9988 - val_loss: 0.0103 - val_acc: 0.9987\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0070 - acc: 0.9990 - val_loss: 0.0093 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0097 - val_acc: 0.9989\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0058 - acc: 0.9993 - val_loss: 0.0096 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 14s 38us/step - loss: 0.1283 - acc: 0.9576 - val_loss: 0.0224 - val_acc: 0.9938\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0237 - acc: 0.9937 - val_loss: 0.0139 - val_acc: 0.9968\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0141 - acc: 0.9970 - val_loss: 0.0119 - val_acc: 0.9980\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0105 - acc: 0.9981 - val_loss: 0.0110 - val_acc: 0.9982\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0084 - acc: 0.9986 - val_loss: 0.0107 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0073 - acc: 0.9990 - val_loss: 0.0098 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0067 - acc: 0.9991 - val_loss: 0.0097 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0059 - acc: 0.9993 - val_loss: 0.0096 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0055 - acc: 0.9993 - val_loss: 0.0092 - val_acc: 0.9990\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0049 - acc: 0.9995 - val_loss: 0.0091 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0089 - val_acc: 0.9993\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0045 - acc: 0.9996 - val_loss: 0.0086 - val_acc: 0.9993\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9993\n",
      "Epoch 15/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0044 - acc: 0.9996 - val_loss: 0.0088 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 14s 38us/step - loss: 0.1300 - acc: 0.9559 - val_loss: 0.0191 - val_acc: 0.9941\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0237 - acc: 0.9937 - val_loss: 0.0131 - val_acc: 0.9973\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0146 - acc: 0.9969 - val_loss: 0.0112 - val_acc: 0.9981\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0109 - acc: 0.9981 - val_loss: 0.0100 - val_acc: 0.9986\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0088 - acc: 0.9985 - val_loss: 0.0102 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0075 - acc: 0.9989 - val_loss: 0.0096 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0065 - acc: 0.9991 - val_loss: 0.0092 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0092 - val_acc: 0.9989\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0058 - acc: 0.9993 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0051 - acc: 0.9995 - val_loss: 0.0088 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0047 - acc: 0.9995 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9992\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0088 - val_acc: 0.9993\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0043 - acc: 0.9996 - val_loss: 0.0089 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 17s 46us/step - loss: 0.1306 - acc: 0.9548 - val_loss: 0.0257 - val_acc: 0.9917\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0265 - acc: 0.9930 - val_loss: 0.0138 - val_acc: 0.9970\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0153 - acc: 0.9967 - val_loss: 0.0117 - val_acc: 0.9980\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0106 - acc: 0.9981 - val_loss: 0.0103 - val_acc: 0.9985\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0081 - acc: 0.9987 - val_loss: 0.0102 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0071 - acc: 0.9990 - val_loss: 0.0092 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0057 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0053 - acc: 0.9994 - val_loss: 0.0093 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 14s 38us/step - loss: 0.0953 - acc: 0.9658 - val_loss: 0.0185 - val_acc: 0.9952\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0181 - acc: 0.9958 - val_loss: 0.0130 - val_acc: 0.9976\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0114 - acc: 0.9980 - val_loss: 0.0109 - val_acc: 0.9985\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0079 - acc: 0.9988 - val_loss: 0.0093 - val_acc: 0.9987\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0067 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9989\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0059 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0090 - val_acc: 0.9991\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 14s 39us/step - loss: 0.1455 - acc: 0.9509 - val_loss: 0.0268 - val_acc: 0.9916\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0263 - acc: 0.9930 - val_loss: 0.0152 - val_acc: 0.9961\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0156 - acc: 0.9964 - val_loss: 0.0126 - val_acc: 0.9976\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0113 - acc: 0.9979 - val_loss: 0.0105 - val_acc: 0.9985\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0088 - acc: 0.9986 - val_loss: 0.0098 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0076 - acc: 0.9989 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 19us/step - loss: 0.0066 - acc: 0.9991 - val_loss: 0.0092 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0056 - acc: 0.9993 - val_loss: 0.0087 - val_acc: 0.9990\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0084 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0049 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 14s 39us/step - loss: 0.1274 - acc: 0.9574 - val_loss: 0.0189 - val_acc: 0.9945\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0232 - acc: 0.9940 - val_loss: 0.0118 - val_acc: 0.9977\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0142 - acc: 0.9970 - val_loss: 0.0107 - val_acc: 0.9982\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0107 - acc: 0.9982 - val_loss: 0.0092 - val_acc: 0.9988\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0080 - acc: 0.9987 - val_loss: 0.0089 - val_acc: 0.9990\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.0093 - val_acc: 0.9990\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0056 - acc: 0.9992 - val_loss: 0.0085 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0053 - acc: 0.9993 - val_loss: 0.0084 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0084 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0084 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 16s 44us/step - loss: 0.1198 - acc: 0.9581 - val_loss: 0.0163 - val_acc: 0.9953\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0225 - acc: 0.9941 - val_loss: 0.0107 - val_acc: 0.9980\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0133 - acc: 0.9973 - val_loss: 0.0105 - val_acc: 0.9985\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0097 - acc: 0.9983 - val_loss: 0.0090 - val_acc: 0.9987\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0074 - acc: 0.9989 - val_loss: 0.0091 - val_acc: 0.9989\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0065 - acc: 0.9991 - val_loss: 0.0096 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 14s 40us/step - loss: 0.1237 - acc: 0.9599 - val_loss: 0.0195 - val_acc: 0.9950\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0235 - acc: 0.9940 - val_loss: 0.0140 - val_acc: 0.9970\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0141 - acc: 0.9969 - val_loss: 0.0113 - val_acc: 0.9980\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0106 - acc: 0.9981 - val_loss: 0.0100 - val_acc: 0.9986\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0085 - acc: 0.9987 - val_loss: 0.0099 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.0092 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0063 - acc: 0.9991 - val_loss: 0.0091 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0058 - acc: 0.9992 - val_loss: 0.0089 - val_acc: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0091 - val_acc: 0.9990\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0084 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0049 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 18s 48us/step - loss: 0.1461 - acc: 0.9505 - val_loss: 0.0210 - val_acc: 0.9937\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0247 - acc: 0.9937 - val_loss: 0.0137 - val_acc: 0.9969\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0151 - acc: 0.9969 - val_loss: 0.0106 - val_acc: 0.9982\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0107 - acc: 0.9982 - val_loss: 0.0108 - val_acc: 0.9984\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0086 - acc: 0.9986 - val_loss: 0.0092 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0073 - acc: 0.9989 - val_loss: 0.0090 - val_acc: 0.9990\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0065 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0058 - acc: 0.9993 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 15s 40us/step - loss: 0.1242 - acc: 0.9548 - val_loss: 0.0184 - val_acc: 0.9947\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0225 - acc: 0.9941 - val_loss: 0.0131 - val_acc: 0.9971\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0140 - acc: 0.9970 - val_loss: 0.0106 - val_acc: 0.9984\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0102 - acc: 0.9982 - val_loss: 0.0097 - val_acc: 0.9987\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0081 - acc: 0.9987 - val_loss: 0.0096 - val_acc: 0.9989\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0068 - acc: 0.9991 - val_loss: 0.0097 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0098 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 15s 41us/step - loss: 0.1358 - acc: 0.9535 - val_loss: 0.0209 - val_acc: 0.9943\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0229 - acc: 0.9941 - val_loss: 0.0130 - val_acc: 0.9972\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0136 - acc: 0.9971 - val_loss: 0.0111 - val_acc: 0.9981\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0101 - acc: 0.9982 - val_loss: 0.0096 - val_acc: 0.9987\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0081 - acc: 0.9987 - val_loss: 0.0093 - val_acc: 0.9989\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0066 - acc: 0.9990 - val_loss: 0.0091 - val_acc: 0.9990\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0059 - acc: 0.9991 - val_loss: 0.0091 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0052 - acc: 0.9993 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0043 - acc: 0.9995 - val_loss: 0.0084 - val_acc: 0.9993\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9993\n",
      "Epoch 14/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0038 - acc: 0.9996 - val_loss: 0.0089 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 16s 45us/step - loss: 0.1271 - acc: 0.9519 - val_loss: 0.0211 - val_acc: 0.9941\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0222 - acc: 0.9943 - val_loss: 0.0139 - val_acc: 0.9971\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0135 - acc: 0.9973 - val_loss: 0.0117 - val_acc: 0.9977\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0097 - acc: 0.9982 - val_loss: 0.0093 - val_acc: 0.9987\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0078 - acc: 0.9989 - val_loss: 0.0093 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0068 - acc: 0.9991 - val_loss: 0.0093 - val_acc: 0.9989\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 15s 41us/step - loss: 0.1294 - acc: 0.9560 - val_loss: 0.0260 - val_acc: 0.9930\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0235 - acc: 0.9937 - val_loss: 0.0168 - val_acc: 0.9962\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0150 - acc: 0.9968 - val_loss: 0.0118 - val_acc: 0.9978\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0106 - acc: 0.9981 - val_loss: 0.0111 - val_acc: 0.9984\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0088 - acc: 0.9986 - val_loss: 0.0102 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 9s 26us/step - loss: 0.0077 - acc: 0.9989 - val_loss: 0.0099 - val_acc: 0.9988\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0066 - acc: 0.9991 - val_loss: 0.0094 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.0086 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0056 - acc: 0.9993 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0049 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9992\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 15s 42us/step - loss: 0.1385 - acc: 0.9513 - val_loss: 0.0198 - val_acc: 0.9940\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0247 - acc: 0.9931 - val_loss: 0.0132 - val_acc: 0.9971\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0153 - acc: 0.9966 - val_loss: 0.0115 - val_acc: 0.9980\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0107 - acc: 0.9980 - val_loss: 0.0099 - val_acc: 0.9986\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0083 - acc: 0.9987 - val_loss: 0.0096 - val_acc: 0.9987\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0071 - acc: 0.9989 - val_loss: 0.0092 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0063 - acc: 0.9991 - val_loss: 0.0090 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0057 - acc: 0.9993 - val_loss: 0.0084 - val_acc: 0.9992\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0085 - val_acc: 0.9993\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 16s 44us/step - loss: 0.1136 - acc: 0.9583 - val_loss: 0.0185 - val_acc: 0.9951\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0202 - acc: 0.9951 - val_loss: 0.0126 - val_acc: 0.9975\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0126 - acc: 0.9976 - val_loss: 0.0106 - val_acc: 0.9985\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0092 - acc: 0.9985 - val_loss: 0.0099 - val_acc: 0.9987\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0076 - acc: 0.9989 - val_loss: 0.0097 - val_acc: 0.9989\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0064 - acc: 0.9991 - val_loss: 0.0095 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0057 - acc: 0.9993 - val_loss: 0.0095 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 0.0088 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0092 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0091 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 15s 42us/step - loss: 0.1118 - acc: 0.9603 - val_loss: 0.0191 - val_acc: 0.9943\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0217 - acc: 0.9944 - val_loss: 0.0121 - val_acc: 0.9973\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0127 - acc: 0.9974 - val_loss: 0.0107 - val_acc: 0.9983\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0099 - acc: 0.9982 - val_loss: 0.0096 - val_acc: 0.9987\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0078 - acc: 0.9988 - val_loss: 0.0098 - val_acc: 0.9988\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0064 - acc: 0.9991 - val_loss: 0.0093 - val_acc: 0.9991\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0059 - acc: 0.9992 - val_loss: 0.0090 - val_acc: 0.9991\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0055 - acc: 0.9993 - val_loss: 0.0092 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9991\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0047 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9992\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 7s 20us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0088 - val_acc: 0.9991\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 18s 48us/step - loss: 0.1706 - acc: 0.9446 - val_loss: 0.0274 - val_acc: 0.9914\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0281 - acc: 0.9921 - val_loss: 0.0169 - val_acc: 0.9959\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0175 - acc: 0.9959 - val_loss: 0.0146 - val_acc: 0.9971\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0126 - acc: 0.9974 - val_loss: 0.0114 - val_acc: 0.9983\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0097 - acc: 0.9983 - val_loss: 0.0111 - val_acc: 0.9986\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 9s 26us/step - loss: 0.0080 - acc: 0.9988 - val_loss: 0.0102 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 10s 26us/step - loss: 0.0073 - acc: 0.9990 - val_loss: 0.0093 - val_acc: 0.9990\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 9s 25us/step - loss: 0.0061 - acc: 0.9992 - val_loss: 0.0092 - val_acc: 0.9990\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 9s 24us/step - loss: 0.0053 - acc: 0.9993 - val_loss: 0.0093 - val_acc: 0.9990\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0095 - val_acc: 0.9990\n",
      "Train on 363930 samples, validate on 45569 samples\n",
      "Epoch 1/30\n",
      "363930/363930 [==============================] - 17s 46us/step - loss: 0.1230 - acc: 0.9561 - val_loss: 0.0215 - val_acc: 0.9937\n",
      "Epoch 2/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0225 - acc: 0.9942 - val_loss: 0.0150 - val_acc: 0.9965\n",
      "Epoch 3/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0138 - acc: 0.9970 - val_loss: 0.0115 - val_acc: 0.9981\n",
      "Epoch 4/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0101 - acc: 0.9981 - val_loss: 0.0107 - val_acc: 0.9983\n",
      "Epoch 5/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0085 - acc: 0.9986 - val_loss: 0.0095 - val_acc: 0.9989\n",
      "Epoch 6/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.0092 - val_acc: 0.9989\n",
      "Epoch 7/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0062 - acc: 0.9991 - val_loss: 0.0094 - val_acc: 0.9989\n",
      "Epoch 8/30\n",
      "363930/363930 [==============================] - 8s 21us/step - loss: 0.0056 - acc: 0.9992 - val_loss: 0.0088 - val_acc: 0.9991\n",
      "Epoch 9/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0088 - val_acc: 0.9990\n",
      "Epoch 10/30\n",
      "363930/363930 [==============================] - 8s 23us/step - loss: 0.0048 - acc: 0.9994 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 11/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0085 - val_acc: 0.9992\n",
      "Epoch 12/30\n",
      "363930/363930 [==============================] - 7s 21us/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0089 - val_acc: 0.9991\n",
      "Epoch 13/30\n",
      "363930/363930 [==============================] - 8s 22us/step - loss: 0.0042 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9991\n",
      "[0.776255707762557, 0.787037037037037, 0.7999999999999999, 0.7922705314009661, 0.8040201005025126, 0.7887323943661971, 0.8200000000000001, 0.8038277511961723, 0.7999999999999999, 0.7962085308056872, 0.8038277511961723, 0.7999999999999999, 0.7850467289719627, 0.7601809954751131, 0.8078817733990147, 0.7767857142857142, 0.8078817733990147, 0.8080808080808082, 0.8159203980099503, 0.7902439024390243, 0.8181818181818183, 0.7980769230769231, 0.7589285714285715, 0.7864077669902914, 0.779342723004695, 0.7741935483870968, 0.8099999999999999, 0.7904761904761906, 0.8121827411167513, 0.8038277511961723, 0.7777777777777777, 0.7942583732057418, 0.783410138248848, 0.8118811881188118, 0.8290155440414508, 0.8020304568527918, 0.8159203980099503, 0.7777777777777777, 0.803921568627451, 0.7962085308056872, 0.7884615384615385, 0.7727272727272727, 0.8038277511961723, 0.8019323671497586, 0.7813953488372092, 0.7887323943661971, 0.7867298578199051, 0.7692307692307693, 0.7555555555555555, 0.7881773399014779, 0.7685185185185185, 0.7510917030567685, 0.814070351758794, 0.7288135593220338, 0.7904761904761906, 0.7884615384615385, 0.779342723004695, 0.7980295566502463, 0.767123287671233, 0.7980295566502463]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "callbacks = [EarlyStopping(monitor='val_loss',mode='min',patience=2, restore_best_weights = True)]\n",
    "results_experimental_accuracy = []\n",
    "for i in range(0,60):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=len(X.columns),kernel_initializer = 'he_normal',activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, kernel_initializer = 'he_normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(keras.optimizers.Adam(lr=0.001),'binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_resampled, Y_resampled,callbacks = callbacks,\n",
    "          epochs=30,validation_data = (X_test_test, Y_test_test),\n",
    "          batch_size=512)\n",
    "\n",
    "    y_test_pred= model.predict(X_test) > 0.5\n",
    "    \n",
    "    f1 = f1_score(Y_test, y_test_pred)\n",
    "    \n",
    "    results_experimental_accuracy.append(f1)\n",
    "    \n",
    "print(results_experimental_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_experimental_accuracy = pd.DataFrame(results_experimental_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Experimental Accuracy: 0    0.791146\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_experimental_accuracy = results_experimental_accuracy.mean()\n",
    "print(\"Mean Experimental Accuracy: {}\".format(mean_experimental_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Experimental Accuracy Results: 0    0.018764\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "std_experimental_accuracy = results_experimental_accuracy.std()\n",
    "print(\"Standard Deviation of Experimental Accuracy Results: {}\".format(std_experimental_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56840    24]\n",
      " [   17    81]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix generation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, y_test_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.77      0.83      0.80        98\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     56962\n",
      "   macro avg       0.89      0.91      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9994834171406589\n",
      "Test Accuracy:0.9991441550176655\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy: {}\\nTest Accuracy:{}'.format(history.history['acc'][-1], history.history['val_acc'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Roc Curve generation\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, y_test_pred)\n",
    "plt.plot ([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label = 'Deep Learning')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Deep Learning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_accuracy= pd.concat([results_control_accuracy, results_experimental_accuracy], axis=1)\n",
    "results_accuracy.columns = ['Control', 'Experimental']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a76440b38>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_accuracy.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a9128aa20>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_accuracy.boxplot(showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = results_accuracy.boxplot()\n",
    "ax.set_ylim([0.9,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1a761715f8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1a914a6ba8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_accuracy.hist(density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control data is normal\n",
      "Experimental data is not normal\n"
     ]
    }
   ],
   "source": [
    "#Normality Testing\n",
    "from scipy import stats\n",
    "\n",
    "alpha = 0.05;\n",
    "\n",
    "s, p = stats.normaltest(results_control_accuracy)\n",
    "if p < alpha:\n",
    "  print('Control data is not normal')\n",
    "else:\n",
    "  print('Control data is normal')\n",
    "\n",
    "s, p = stats.normaltest(results_experimental_accuracy)\n",
    "if p < alpha:\n",
    "  print('Experimental data is not normal')\n",
    "else:\n",
    "  print('Experimental data is normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null hypothesis rejected, significant difference between the data-sets\n"
     ]
    }
   ],
   "source": [
    "#Significance Testing\n",
    "s, p = stats.wilcoxon(results_control_accuracy[0], results_experimental_accuracy[0])\n",
    "\n",
    "if p < 0.05:\n",
    "  print('null hypothesis rejected, significant difference between the data-sets')\n",
    "else:\n",
    "  print('null hypothesis accepted, no significant difference between the data-sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
